\chapter{Marco Teórico}

\section{Estacionalidad}

El componente estacional consiste en efectos que son razonablemente estables con respecto al
tiempo, la dirección y la magnitud. Surge de influencias sistemáticas relacionadas con el
calendario.

También incluye efectos sistemáticos relacionados con el calendario que no son estables en su
calendario anual o que son causados por variaciones en el calendario de un año a otro, tales
como: la Navidad, el inicio y fin del curso escolar, el número de días por mes, las
vacaciones y días festivos que ocurren cada año pero pueden variar en el calendario.

\im{¿Cómo identificamos la estacionalidad?}
 
La estacionalidad en una serie temporal puede identificarse mediante picos y valles
regularmente espaciados que tienen una dirección constante y aproximadamente la misma
magnitud cada año, en relación con la tendencia.
 
\im{¿Qué es el ajuste estacional y por qué lo necesitamos?}

El ajuste estacional es el proceso de estimar y luego eliminar de una serie de tiempo las
influencias que son sistemáticas y relacionadas con el calendario. Los datos observados deben
ajustarse estacionalmente ya que los efectos estacionales pueden ocultar tanto el verdadero
movimiento subyacente en la serie, como ciertas características no estacionales que pueden
ser de interés para los analistas.
 
\im{Manchas solares}

A continuación, agrega las órdenes necesarias para generar un gráfico de la serie de tiempo y
un gráfico de la ACF (correlograma) para los datos sunspot.year que vienen precargados en R.

Recuerda que la ciclicidad induce picos en la duración promedio del ciclo. 

<<>>=
autoplot(sunspot.year)
ggAcf(sunspot.year)
@

Al observar el gráfico ACF mira cómo cambian las correlaciones a medida que aumenta el
retraso, ¿en qué valor de retraso puedes encontrar la autocorrelación máxima? ¿puedes ver
alguna estacionalidad, ciclicidad y/o tendencia? ¿Qué comportamiento puedes identificar?

\begin{shaded}
Primero, vemos en la gráfica que la serie tiene patrones \textbf{cíclicos}. Recordemos que
un ciclo ocurre cuando los datos exhiben subidas y bajadas que no tienen una frecuencia fija.
Estas fluctuaciones generalmente se deben a las condiciones económicas y, a menudo, están
relacionadas con el "ciclo económico". La duración de estas fluctuaciones suele ser de al
menos 2 años. La serie anual de manchas solares sigue un ciclo de aproximadamente 10-11 años,
esto causa un pico en el retardo o LAG 10-11 en el gráfico de autocorrelación ACF.
\end{shaded}


\im{Muertes accidentales en EE.UU}

La estacionalidad induce picos en los \textbf{retardos estacionales}. Piensa en las
vacaciones, cada día festivo tendrá ciertos productos que alcanzan su punto máximo en ese
momento cada año y, por lo tanto, la correlación más fuerte será los valores en ese mismo
momento cada año.

Utiliza los datos USAccDeaths (precargados en R) sobre mortalidad mensual por accidentes en
EE.UU. en 1973–1978 y detecta cuál es la estacionalidad de los datos. Para ello, rellena los
espacios a continuación y ejecuta las órdenes en R.
 

<<>>=
autoplot(USAccDeaths)
ggAcf(USAccDeaths)
@
 
¿Qué estacionalidad tienen los datos?

\begin{shaded}
Observamos un comportamiento estacional cada 6 meses, esto causa un pico en el retardo o LAG
6 en el correlograma.
\end{shaded}

Recuerda que el gráficos de autocorrelación ACF nos ayuda a identificar las características
de las series temporales.

Con esto en mente, observa los siguientes gráficos y haz coincidir los gráficos ACF que se
muestran (A-C) con sus gráficos de tiempo correspondientes (1-3).


\begin{figure}[H]
\includegraphics[width = \linewidth]{ts_acf}
\caption{Interpretación de resultados}
   \label{fig:iden}
\end{figure}

\begin{shaded}
1-B, 2-A y 3-C
\end{shaded}

\section{Estacionariedad}

\im{¿Qué es una serie estacionaria?}

En general, se dice que una serie temporal es estacionaria cuando es "estable", es decir,
cuando se comporta de manera similar de un período de tiempo a otro y sus propiedades no
dependen del momento en que se observa la serie.

En el contexto de series temporales, la estacionariedad se refiere a: la estabilidad de la
media (es decir, a que no haya una tendencia) y la estabilidad de la correlación (es decir,
la estructura de correlación de los datos permanece constante en el tiempo).

Entonces, tenemos los siguientes casos:

 \begin{itemize}[itemsep=1ex]
  \item \textbf{Serie estacionaria:} si los datos varían alrededor un mismo valor promedio y
  con la misma variabilidad.
  \item \textbf{Serie no estacionaria:} si la media y/o la varianza cambian a lo largo del
  tiempo.
 \end{itemize}
 
\im{¿Por qué nos interesa que la serie sea estacionaria?} 

Cuando una serie temporal es estacionaria, puede ser más fácil modelarla. 


Los métodos de modelado estadístico suponen o requieren que las series temporales sean
estacionarias para ser efectivos.

A grandes rasgos verificar esta propiedad en el estudio de las series de tiempo tiene su
importancia en los siguientes aspectos.

 \begin{itemize}[itemsep=1ex]
  \item \textbf{Facilidad de Análisis:} las series estacionarios pueden modelarse con pocos
  parámetros.
  \item \textbf{Mejor Entendimiento:} las series temporales tienen distribución estable en el
  tiempo, es decir, las características estadísticas de nuestra serie de tiempo (media,
  varianza y autocorrelación) serán las mismas tanto en el futuro como en el pasado.
  \item \textbf{Ubicuidad:} la estacionariedad nos permite generalizar nuestros resultados al
  campo de estudio, no sólo limitarnos al problema que estemos analizando.
 \end{itemize}
 
En el caso de que se incumpla el supuesto de estacionariedad, debemos estacionarizar las
series de tiempo antes de ajustar un modelo. Veremos más adelante cómo hacerlo.

\im{¿Cómo identificar si una serie es estacionaria?}

Podemos evaluar la estacionariedad mediante gráficos y/o pruebas estadísticas. Si la serie es
estacionaria, los gráficos de tiempo mostrarán que la serie es aproximadamente horizontal
(aunque es posible algún comportamiento cíclico), con una variación constante (sin tendencia
ni estacionalidad). Para una serie temporal estacionaria, además el gráfico de
autocorrelación ACF caerá a cero relativamente rápido, mientras que la ACF de datos no
estacionarios disminuye lentamente.

Para evaluar la estacionariedad en conjuntos de datos donde las tendencias y las
estacionalidades son difíciles de ver, puede ser bastante útil evaluar la autocorrelación de
la serie temporal. Podemos entonces observar el correlograma de la serie temporal para
evaluar su estacionariedad.

Analiza la estacionariedad de las desviaciones de la temperatura media global tierra-océano
(gtemp del paquete astsa)

\section{Autocorrelación}

La esencia de la \textbf{correlación serial (autocorrelación)} es que deseamos ver cómo se
afectan entre sí las observaciones secuenciales en una serie temporal. Si podemos encontrar
patrones (estructura) en estas observaciones, entonces probablemente nos ayudará a mejorar
nuestros modelos y predicciones.

Algunos \textbf{patrones que hemos detectado en el correlograma} se pueden resumir a
continuación:


 \begin{itemize}[itemsep=1ex]
 
  \item Las tendencias fuertes darán lugar a que las observaciones más recientes tengan un
  valor más cercano entre sí. El gráfico ACF de las series temporales con \textbf{tendencia}
  tiende a tener valores positivos en los primeros retardos que disminuyen lentamente a
  medida que aumentan los retardos.
  
  \item Cuando la serie es \textbf{estacional}, en el gráfico ACF las autocorrelaciones serán
  mayores en los retardos estacionales (es decir, en múltiplos de la frecuencia estacional).
  Piensa en las vacaciones, cada día festivo tendrá ciertos productos que alcanzan su punto
  máximo de venta en ese momento cada año y, por lo tanto, la correlación más fuerte será los
  valores en ese mismo momento cada año.
  
  \item Cuando los datos tienen \textbf{tendencia y estacionalidad}, observamos una
  combinación de los dos efectos anteriores.
  
  \item De manera similar a lo que ocurre con la estacionalidad, cuando la serie es
  \textbf{cíclica}, veremos que en el gráfico ACF las autocorrelaciones serán mayores en la
  duración promedio del ciclo.
  
 \end{itemize}

<<>>=
autoplot(fma::mink)
ggAcf(fma::mink)
@

\begin{shaded}
La población de visones presenta ciclos (picos) cada 10 años aproximadamente, esto causa un
pico cercano al retardo o LAG 10 en el gráfico de autocorrelación ACF.
\end{shaded}


<<>>=
pigs.ts <- ts(fma::pigs[121:188], start = c(1990, 1), frequency = 12)
autoplot(pigs.ts)
@

El gráfico muestra una ligera tendencia a lo largo del tiempo, pero no está claro.

<<>>=
ggAcf(pigs.ts)
@

Sin embargo, el gráfico de la ACF hace que el patrón sea más claro.

\begin{shaded}
Hay más información en el gráfico ACF que en el diagrama de serie de tiempo simple. Vemos que
los primeros tres retardos superan claramente la línea azul, lo que sugiere que es posible
alguna señal en este componente de la serie de tiempo que se puede utilizar para crear un
modelo.
\end{shaded}

<<>>=
Box.test(fma::pigs, lag = 24, fitdf = 0, type = "Lj")
@

\begin{shaded}
El p-valor de la prueba es estadísticamente significativo (p < 001), por lo tanto, esto
respalda lo que hemos visto en el gráfico ACF anterior, la serie temporal muestra un patrón
de comportamiento particular que podemos utilizar para su modelado.
\end{shaded}


<<>>=
autoplot(astsa::gtemp)
ggAcf(astsa::gtemp)
@

<<>>=
Box.test(astsa::gtemp, lag = 22, type = "Lj")
@

\begin{shaded}
Los datos muestran una tendencia y por tanto no son estacionarios.
\end{shaded}


\im{Terminología}

 \begin{itemize}[itemsep=1ex]
  
  \item La autocorrelación también se llama \textbf{correlación en serie}. Este tipo de
  correlación se utiliza para comprender cómo las observaciones de series temporales dependen
  de los valores de la misma serie en momentos anteriores.
  
  \item Las observaciones pasadas de la serie se denominan retrasos o retardos o lag.
  
  \item Un proceso es \textbf{ergódico} cuando conforme k se hace más grande, la
  autocorrelación se hace más pequeña. Es decir, que la dependencia entre variables tiene
  menos importancia pasado más tiempo.
  
 \end{itemize}

\section{Transformaciones}

Hemos visto qué es la estacionariedad y las ventajas que presentan las series estacionarias
cuando queremos modelar y predecir. Sin embargo, \textbf{las series temporales generalmente
no son estacionarias.}

\im{¿Cómo hacer una serie temporal estacionaria?}

A menos que tu serie temporal sea estacionaria, no puedes construir un modelo de serie
temporal. Esta es la razón por la que estudiamos la estacionariedad antes de hablar de
modelos de series temporales.

Las series temporales con tendencias, o con estacionalidad, no son estacionarias: la
tendencia y la estacionalidad afectarán el valor de la serie temporal en diferentes momentos.

En los casos en que se incumple el supuesto de estacionariedad, el primer requisito es
estacionarizar la serie de tiempo. Hay múltiples formas de hacer que tus datos sean
estacionarios. Por ejemplo, podemos transformar la serie tomando diferencias (anuales o
estacionales) y logaritmos para estacionarizar una serie temporal.

Cuando se aplican tanto las diferencias estacionales como las diferencias regulares (o
diferencias primeras), no importa qué se haga primero: el resultado será el mismo. Sin
embargo, si los datos tienen un patrón estacional fuerte, \textbf{recomendamos que la
diferenciación estacional se haga primero}, porque la serie resultante a veces será
estacionaria y no habrá necesidad de una primera diferencia adicional. Si primero se hace la
diferenciación, todavía habrá presente estacionalidad.

\im{Diferencia estacional}

Una forma de \textbf{desestacionalizar} es tomar una \textbf{diferencia estacional}. Es
decir, podemos calcular la diferencia entre el valor de la serie en un mes del año respecto
al mismo mes del año anterior. Recuerda que siempre se pierde el primer dato de la serie en
la diferenciación.

\begin{center}
\ti{diff(x, lag = 1, differences = 1, ...)}
\end{center}

La función diff() permite especificar el retardo (lag) y el orden (differences) de las
diferencias. El argumento lag especifica si tomamos diferencias en 1 tiempo o más (por
defecto es 1), mientras que el argumento differences refiere a si tomamos diferencias anuales
(1), mensuales (12), etc..

\im{Cálculo de la tasa de cambio de la serie}

\begin{center}
\textbf{Primera diferencia del logaritmo = cambio porcentual}
\end{center}

Cuando aplicamos el logaritmo junto con la diferenciación de la serie pasamos de tener
diferencias absolutas a obtener diferencias relativas (es decir, porcentajes). Por tanto, la
serie diff(log(x)) representa el cambio porcentual en "x" de un período a otro.

Esto es porque el cambio porcentual en "x" en el período "t", definido como (X(t) -X(t-1)) /
X(t-1), es aproximadamente igual a log(X(t)) - log(X(t-1)), cuando el cambio porcentual
es pequeño. En términos estadísticos, esto significa que es virtualmente idéntico a diff(
log(x)).

Esta transformación nos permite comparar "manzanas con manzanas" entre acciones, índices o
cualquier otra serie.

\section{Autocorrelación parcial}

\im{¿Qué es un modelo de series de tiempo?}

Esencialmente, es un modelo estadístico que intenta "explicar" la correlación serial presente
en una serie de tiempo.

Para la selección de un modelo de serie temporal nos valdremos de los patrones identificados
en la serie de tiempo y su correlograma. Pero además, debemos conocer y considerar una amplia
variedad de modelos, incluidos sus supuestos y su complejidad, para elegir el "más simple"
que explique la correlación serial.

\subsection{White Noise (WN)}

Entonces, comencemos por el modelo más sencillo de series temporales, el modelo de
\textbf{ruido blanco.}

Las series de tiempo que no muestran autocorrelación (correlograma sin picos), tienen media
(cero) y varianza constante (simga2), tienen un comportamiento similar al ruido blanco. Se
dice que los elementos de la serie son independientes e idénticamente distribuidos (iid).

El punto clave del modelo de ruido blanco es que lo utilizaremos como modelo para los
residuos. Se espera que los datos de series de tiempo contengan algún componente de ruido
blanco además de la señal generada por el proceso subyacente. Por lo tanto, buscaremos
ajustar otros modelos de series de tiempo a nuestra serie observada, y usaremos el modelo de
ruido blanco sobre los residuos como confirmación de que hemos eliminado cualquier
correlación serial restante, indicándonos que tenemos un buen ajuste del modelo.

\im{¿Cómo podemos saber si el modelo de ruido blanco se ajusta bien a nuestros datos?}

Una serie de tiempo es ruido blanco \textbf{si las variables son independientes y están
distribuidas de manera idéntica con una media de cero.} Esto significa que todas las
variables tienen la \textbf{misma varianza (sigma2)} y cada valor tiene una
\textbf{correlación cero} con todos los demás valores de la serie.

<<>>=
autoplot(fma::dj)
@

\begin{shaded}
Los datos no se comportan como una serie de ruido blanco, no tienen media y varianza
constante. Analicemos ahora la autocorrelación con el gráfico de la ACF.
\end{shaded}

<<>>=
ggAcf(fma::dj)
@

\begin{shaded}
Varias correlaciones son significativas.
Por último aplicamos la prueba Q de Ljung-Box que hemos visto en la lección anterior, donde
la hipótesis nula (H0) indicaba que las autocorrelaciones, hasta un retarlo o lag d, son
iguales a cero. Utilizamos la función Box.test del paquete stats que viene instalado por
defecto en R.
\end{shaded}

<<>>=
Box.test(fma::dj, lag = 10, type = "Ljung-Box")
@

\begin{shaded}
Como p < 0.05, rechazamos la hipótesis nula y por tanto existe correlación para algún retardo
menor que 10. Existe autocorrelación en la serie temporal, información que puede ser
interesante capturar en un modelo.
\end{shaded}

\subsection{Random Walk (RW)}

Anteriormente hemos visto que el ruido blanco es un modelo adecuado para series estacionarias
y sin correlación serial. Ahora veremos la caminata aleatoria (Random Walk, RW), el modelo
más sencillo de serie no estacionaria.

Una caminata aleatoria es el modelo de series de tiempo más sencillo para series no
estacionarias, donde la observación actual es igual a la observación anterior con un paso
aleatorio hacia arriba o hacia abajo.

Más formalmente, una caminata aleatoria es un modelo de serie temporal Xt tal que:

\begin{equation}
   \bm{X_{t} = c + X_{t-1} + w_{t}}
   \label{rw}
\end{equation}

donde c es una constante y wt es una serie discreta de ruido blanco.

Hay dos tipos de caminatas aleatorias: 

 \begin{itemize}[itemsep=1ex]
  \item \textbf{La caminata aleatoria sin deriva} (es decir, sin término constante o de
  ordenada al origen), y
  \item \textbf{La caminata aleatoria con deriva} (es decir, hay un término constante).
 \end{itemize}

Las propiedades de las series de caminara aleatoria son un poco más interesantes que las del
ruido blanco. Si bien la media de una caminata aleatoria sigue siendo cero, \textbf{la
covarianza ahora depende del tiempo. A medida que aumenta el tiempo, también lo hace la
varianza.} Por lo tanto, tendrá poco sentido extrapolar las "tendencias" en ellos a largo
plazo, ya que toman, literalmente, caminos al azar. Otra características de estas series es
que el correlograma mostrará una \textbf{autocorrelación alta que disminuye lentamente a
medida que aumentan los retardos.}

El modelo de caminata aleatoria (RW) también es un modelo básico de series de tiempo. Es la
suma acumulada (o integración) de una serie de ruido blanco medio cero (WN), de modo que la
primera serie de diferencias de un RW es una serie WN.

\im{¿Cómo podemos saber si el modelo de caminata aleatoria se ajusta bien a nuestros datos?}

Bueno, usamos la definición de un caminara aleatoria, que es simplemente que la diferencia
entre dos valores consecutivos es igual a la realización de un proceso de ruido blanco
discreto. Si creamos una serie con las diferencias de los valores de nuestra serie,
deberíamos tener una serie que se parezca al ruido blanco discreto. Es decir, cuando
graficamos el correlograma, buscamos evidencia de ruido blanco discreto, es decir, una serie
de residuos que no está correlacionada en serie.

\im{Ejemplo}

Continuemos con los datos del índice de Dow Jones. Anteriormente hemos visto que este índice
no sigue un modelo de ruido blanco. Veamos ahora si pueden comportarse como un modelo de
caminata aleatoria. Si este fuera el caso, \textbf{los cambios diarios en el índice DJ
deberían tener un comportamiento similar al ruido blanco.}

Probemos con transformar la serie para obtener los \textbf{cambios diarios en el índice.} Usa
la siguiente transformación en primeras diferencias:

<<>>=
ddj <- diff(fma::dj)
@

La función \texttt{diff()} toma la diferencia entre mediciones consecutivas, se conoce como
diferenciación o primeras diferencias. Recuerda que la diferenciación puede ayudar a
estabilizar la media al eliminar o reducir la tendencia y la estacionalidad, lo que podría
dejar solo ruido blanco.

Graficamos los datos diferenciados y su ACF. 

<<>>=
autoplot(ddj)
@

\begin{shaded}
Los cambios diarios en el índice Dow Jones ocurren de manera aleatoria, con algunos cambios
de mayor amplitud a lo largo del período.
\end{shaded}

<<>>=
ggAcf(ddj)
@

\begin{shaded}
El gráfico ACF de ddj no muestra patrones aparentes. A excepción de la correlación para el
retardo 6 (LGA6), ningún otro coeficiente de autocorrelación supera la línea azul punteada,
lo que implica que las autocorrelaciones de los cambios diarios valen cero con un nivel de
confianza del 95\%.
\end{shaded}

\textbf{NOTA:} recuerda que se trata de un nivel de confianza, en este caso al 95\%, por lo
que 1 de las 25 observaciones se pueden ubicar fuera del límite del 95\% solo por azar. Por
lo tanto, los cambios diarios parecen ser ruido blanco a pesar de que la correlación para el
LAG 6 sea significativa.

Aplicamos por último la prueba Q de Ljung-Box para evaluar la autocorrelación de los datos.

<<>>=
Box.test(ddj, lag = 10, type = "Ljung-Box")
@

\begin{shaded}
Vemos que no se rechaza la hipótesis nula de ausencia de autocorrelación hasta el retardo
indicado (lag = 10).
\end{shaded}

\subsection{PACF}

Dos instrumentos para identificar la dinámica de una serie temporal son: La función de
autocorrelación (ACF: AutoCorrelation Function) y la función de autocorrelación parcial o
(PACF: Partial AutoCorrelation Function).

Hemos hablado del ACF en otros vídeos, mide la correlación entre la observación en el momento
actual y las observaciones en tiempos anteriores.

Una descripción intuitiva del PACF es que \textbf{"representa la cantidad de correlación con
cada retardo que no se explica por retardos más recientes"}. Por tanto, es una correlación
parcial o condicional.

\begin{figure}[H]
\includegraphics[width = \linewidth]{acf_pacf}
\caption{Diferencia entre ACF y PACF}
   \label{fig:diffpacf}
\end{figure}

\im{¿Cómo usar el PACF en pronósticos de series de tiempo?}

Imagina que queremos determinar cuántos retardos pasados (o lags) debemos incluir en nuestro
modelo para predecir la temperatura global (datos gtemp de R).

Observamos el autocorrelograma ACF de la serie de temperatura global:

<<>>=
ggAcf(astsa::gtemp)
@

\begin{shaded}
El gráfico ACF muestra un decaimiento suave de la autocorrelación, vemos que las
autocorrelaciones son significativas para un gran número de rezagos, lo que se llama
\textbf{persistencia.}
\end{shaded}

Entonces nos preguntamos, ¿realmente será necesario incluir tantos tiempos pasados para
predecir la temperatura global? ¿o las autocorrelaciones en los retardos superiores se pueden
deber simplemente a la propagación de la autocorrelación en retardos bajos?

Para responder a esta pregunta utilizamos el autocorrelograma parcial PACF. 

<<>>=
ggPacf(astsa::gtemp)
@

\begin{shaded}
El gráfico PACF tiene dos picos significativos, en el retraso 1 y 2, lo que significa que
todas las autocorrelaciones de orden superior que vimos en el ACF se explican realmente por
la autocorrelación del retraso 1 y 2. Esto se conoce como el \textbf{orden} de un modelo
autorregresivo (AR), (tranquilos, veremos estos modelos más adelante).
\end{shaded}

\section{Modelos AR, MA y ARMA}

En algunos casos un modelo de ruido blanco o de caminata aleatoria es insuficiente para
capturar el comportamiento de autocorrelación completo de una serie temporal. En estos casos
se necesitan modelos más sofisticados.

En esta sección vamos a discutir 2 tipos de modelo: el modelo autorregresivo (AR), el modelo
de  media móvil (MA) y el modelo de mixto de autogresivo de media móvil (ARMA).

\subsection{Modelo autorregresivo AR(p)}

Para datos estacionarios, uno de los modelos más sencillos que permite modelar la dependencia
de los valores de una serie temporal con su pasado es el modelo autorregresivo (AutoRegresive
Models, AR).

Un modelo autorregresivo AR es simplemente una \textbf{regresión lineal múltiple} de una
serie de tiempo con los \textbf{valores de la serie en tiempos anteriores (llamados retardos
o lags) como predictores.} Entonces, \textbf{las últimas p observaciones} se usan como
predictores en la ecuación de regresión. Se dice que "p" es el orden del modelo
autorregresivo.

Descubrimos que los modelos AR pueden generar un \textbf{amplio repertorio de patrones} según
los valores de sus parámetros. Hemos visto que existen restricciones de los parámetros de los
modelos AR para datos estacionarios.

NOTA: fíjate que el modelo autorregresivo es simplemente una extensión de la caminata
aleatoria, que incluye términos más atrás en el tiempo.

\im{¿Cómo identificar y ajustar un modelo AR(p)?}

\begin{shaded}
\textbf{En una serie estacionaria con un proceso AR puro la ACF decae de manera exponencial o
\ro{sinusoidal}, mientras que la PACF se cortará en el retardo p.}
\end{shaded}

Cuando conoces el orden (estructura) del modelo, puedes ajustar un modelo con la función
Arima() del paquete forecast.

\begin{center}
\ti{Arima(y, order = c(0, 0, 0), include.mean = TRUE, include.drift = FALSE, ...)}
\end{center}

Para ajustar un modelo AR(p) utilizamos la función \ti{Arima()} de R, indicándole el orden
\textbf{c(p,0,0)}. El resto de los argumentos son los datos ("y"), \ti{include.mean = TRUE}
significa que la media no es cero, y si especificas \ti{include.drift = TRUE} se ajusta un
modelo que fluctúa alrededor de una tendencia (hacia arriba o hacia abajo)

El resultado mostrará la \textbf{estimación de los parámetros del modelo:} la/s pendiente/s
\textbf{phi} (indicada por las columnas ar1, ar2, ...), el intercepto (o media) y la varianza
del ruido (sigma2). También tenemos información sobre el error estándar de estas
estimaciones, la verosimilitud (Log Lik) y el coeficiente de información de Akaike del modelo
(AIC).

Para predecir con este modelo utilizamos la función \ti{forecast()} del paquete forecast:

\begin{center}
\ti{forecast(objeto, h, ...)}
\end{center}

donde debes especificar el objeto que hayas creado con el ajuste del modelo como argumento, y
puedes indicar el horizonte de pronóstico con el argumento h.

\im{Ejemplo}

<<fig.width=7, fig.asp=0.7>>=
sunspot.year |> 
 as_tsibble() |> 
 gg_tsdisplay(y = value, plot_type = "partial")
@

\begin{shaded}
Vemos que el número de manchas solares parece tener un comportamiento autorregresivo, el ACF
decae (con un comportamiento sinusoidal) mientras que el PACF se corta en 3.
\end{shaded}

Probemos primero ajustar el modelo más sencillo, un AR(1). Más adelante probaremos con los
modelos AR(2) y AR(3) y compararemos los resultados. Recuerda que el modelo AR(1) viene dado
por la siguiente ecuación:

\begin{equation}
   \bm{Y_{t} = c + \phi \ast Y_{t-1} + \epsilon_{t}}
   \label{ar1}
\end{equation}

Para ajustar el modelo utilizamos la función Arima indicándole un 1 en el primer argumento
del orden del modelo (los otros dos argumentos los veremos más adelante, cuando profundicemos
en los modelos ARIMA, por ahora quédate con la idea de que el primer valor que se le da al
argumento "order" es el orden de la parte autorregresiva del modelo).

<<>>=
Arima(sunspot.year, order = c(1, 0, 0))
@

Veamos el mismo resultado, pero con la función \ti{ARIMA} del paquete
$\left \{fable \right \}$

<<>>=
sun_tb <- sunspot.year |> 
 as_tsibble()
@

Probemos ajustando varios modelos

<<>>=
sun_fit <- sun_tb |> 
 model(modelo1  = ARIMA(value ~ 1 + pdq(1, 0, 0)),
       stepwise = ARIMA(value),
       busqueda = ARIMA(value, stepwise = FALSE))
@



<<>>=
sun_fit |> tabla(cap = "Modelos ajustados")
@

Coloquemoslo de forma tal que sea más fácil ver el orden

<<>>=
sun_fit |> 
 pivot_longer(cols = everything(), 
          names_to = "modelo",
          values_to = "orden") |> 
 tabla(cap = "Modelos ajustados")
@

<<>>=
c(t1, t2) %<-% ajustar_modelos(sun_fit, fun_list)
@

<<>>=
t1 |> tabla(cap = "coeficientes")
@


<<>>=
t2 |> tabla(cap = "bondad de ajuste")
@


\begin{shaded}
Aquel modelo con menor AIC será el más parsimonioso y por tanto el que se recomendará
seleccionar.
\end{shaded}

En la tabla de coeficientes vemos que el valor de $\phi = 0.8196$, la constante $c = 8.78$,
aunque la función original de ARIMA me regresa 48.69. 

\begin{shaded}
La función de Fable \ti{ARIMA()} utiliza una parametrización alternativa de constantes para
\ti{stats::arima()} y \ti{forecast::Arima()}. Si bien las parametrizaciones son equivalentes,
los coeficientes para la constante/media serán diferentes. Ver \url{https://bit.ly/36gbLP3}
\end{shaded}


$$Y_{t} = 48.6986 + 0.8196 \ast Y_{t-1} + \epsilon_{t}$$


Para evaluar visualmente qué tan bien se ajusta el modelo que hemos creado a nuestros datos,
vamos a graficar los valores ajustados junto con los valores observados (esta es una
aproximación muy simple, más adelante en el temario veremos aproximaciones más sofisticadas
para evaluar el ajuste del modelo).

Después de evaluar y seleccionar el modelo, debemos ajustar únicamente ese, ya que no fue
posible (por el momento) realizar el ajuste a partir del objeto que contiene más modelos.

<<>>=
sun_mod <- sun_tb |> 
 model(modelo1  = ARIMA(value ~ 1 + pdq(1, 0, 0)))
@


<<hola>>=
sun_tb |>
 autoplot(value) +
 autolayer(fitted(report(sun_mod)), color = "orange")
@

Esto da un warning, así que lo mejor será usar la opción Arima

<<>>=
(fit <- Arima(sunspot.year, order=c(1,0,0)))
@


<<>>=
autoplot(sunspot.year) + autolayer(fitted(fit),series = "Fitted")
@

Vemos que el modelo logra capturar bastante bien el comportamiento principal de la serie de
datos de manchas solares.

Podemos incluso realizar una predicción sencilla con este modelo y grafificarla:

<<>>=
autoplot(forecast(fit))
@

Vemos que para el período 1989-1999 es de esperar una disminución en el número de manchas
solares.

\subsection{Comparación de modelos}

Hasta ahora hemos visto cómo ajustar un modelo autorregresivo AR(p) pero a menudo tenemos
varios modelos candidatos que queremos comparar. Para comparar modelos de series temporales
podemos utilizar distintos criterios, como el criterio de información de Akaike AIC, el
criterio de información de Akaike corregido AICc o el criterio de información Bayesiana BIC.

\im{¿Qué es el criterio de información de Akaike (AIC)?}

El AIC ("Akaike’s Information Criterion") sirve para comparar modelos. Este criterio tiene en
cuenta tanto el ajuste del modelo como su complejidad de acuerdo a la fórmula:

\begin{equation}
   \bm{AIC = -2 \ast log - likelihood + 2 \ast p}
   \label{aic2}
\end{equation}

donde el primer término mide el ajuste (es la devianza) y el segundo la complejidad (p es el
número de parámetros en el modelo). Es decir, el segundo término es de penalización y evita
el sobreajuste (i.e. si aumenta el número de parámetros del modelo suele mejorar la bondad
del ajuste sin implicar una mejoría del modelo).

Existe también el AIC corregido (AICc) que es una variante del AIC para tamaños muestrales
pequeños (pocos datos).

\im{Cómo se interpreta el AIC}

El AIC se funda en la teoría de la información. Cuando se utiliza un modelo estadístico para
representar el proceso que generó los datos, la representación casi nunca será exacta; por lo
que se perderá cierta información al utilizar el modelo para representar el proceso. El AIC
calcula la cantidad relativa de información perdida por un modelo dado: cuanta menos
información pierde un modelo, mayor es la calidad de ese modelo. Al estimar la cantidad de
información perdida por un modelo, el AIC se ocupa de la compensación entre la bondad de
ajuste del modelo y la simplicidad del modelo. En otras palabras, el AIC se ocupa tanto del
riesgo de sobreajuste como del riesgo de subajuste.

El valor específico del AIC no nos brinda información, ya que dependerá de las unidades de
medida de la variable considerada. La utilidad del AIC es en la comparación entre modelos.
Debemos elegir aquel modelo más parsimonioso que presente menor AIC, considerando que es
“suficiente” una diferencia de 2 puntos (algo que se desprende de la ecuación del AIC).

El AIC no equivale a significación (p-valor), se plantea dentro de una concepción de la
estadística distinta y alternativa. El AIC no proporciona una prueba de un modelo en el
sentido de probar una hipótesis nula , es decir el AIC no puede decir nada acerca de la
calidad del modelo en un sentido absoluto. Si todos los modelos candidatos encajan mal, el
AIC no dará ningún aviso de ello.

\im{¿Qué es el Criterio de información bayesiano de Schwarz (BIC)?}

Una medida relacionada es el criterio de información bayesiano de Schwarz:

\begin{equation}
   \bm{BIC = -2 \ast log - likelihood + log(n) \ast p}
   \label{bic}
\end{equation}

dónde  n es el número de observaciones utilizadas para la estimación. Si comparas con la
ecuación del AIC verás que considera una penalización mayor (log(n) en lugar de 2). Debido a
la mayor penalización, el modelo elegido por BIC será el mismo que el elegido por AIC o uno
con menos términos.

\im{Ejemplo}

En el ejemplo anterior estudiamos el comportamiento de la serie anual de manchas solares
(sunspot.year) desde 1700 a 1988.  Los gráficos de la serie sugerían un modelo
autorregresivo de orden 1, 2 o 3.

\im{¿Cómo puedes determinar qué modelo AR es más apropiado en la práctica?}

Para comparar los modelos candidatos AR(1), AR(2) y AR(3), primero ajustamos estos 3 modelos:

<<>>=
(fit1 <- Arima(sunspot.year, order = c(1, 0 , 0)))
(fit2 <- Arima(sunspot.year, order = c(2, 0 , 0)))
(fit3 <- Arima(sunspot.year, order = c(3, 0 , 0)))
@

\begin{shaded}
Compara estos 3 modelos posibles mediante los estadísticos AIC, AICc y BIC que acabamos de
definir en la página anterior. La idea principal es que estos indicadores penalizan los
modelos para un mayor número de parámetros, para evitar el sobreajuste, y se prefieren
valores más pequeños. Es decir, si el resto de factores permanecen iguales, \textbf{un modelo
que produce un AIC o BIC más bajo que otro modelo se considera un mejor ajuste.} NOTA: este
procedimiento también puede ser útil para comparar distintos tipos de modelo, por ejemplo un
AR con un MA. Más adelante veremos cómo comparar los modelos en función de su capacidad de
pronóstico. 
\end{shaded}

\begin{shaded}
\textbf{Elegimos el modelo más parsimonioso (más sencillo), que es AR(2) en este caso.}
\end{shaded}

El mejor modelo es aquel con menor AIC y más parsimonioso

\subsection{Modelo de medias móviles (MA)}

Otro modelo para datos estacionarios es el modelo de medias móviles (Moving Average, MA) ,
que también permite modelar la dependencia temporal de la serie a partir de valores pasados,
como el AR, pero aquí utiliza los errores del pasado. Es decir, corrige pronósticos futuros
basados en errores cometidos en pronósticos recientes (que en realidad no se observan).

Al igual que el modelo AR que vimos anteriormente, un modelo de media móvil (moving average
MA) también puede considerarse como una regresión. Pero para el MA de orden q MA(q), en lugar
de tomar las observaciones de tiempos anteriores para crear el modelo, tomamos los errores
del pronóstico de tiempos anteriores.

Es decir, el modelo de media móvil (MA) es un modelo de regresión múltiple con errores en
retardo como predictores: corrige pronósticos futuros basados en errores cometidos en
pronósticos recientes.

Descubrimos que los modelos MA también pueden generar un amplio repertorio de patrones según
los valores de sus parámetros. Hemos visto que existen restricciones de los parámetros de los
modelos MA para datos estacionarios.

NOTA: (no lo confundas este modelo con el suavizado de medias móviles).

\begin{shaded}
En una serie estacionaria con un proceso MA puro la ACF se cortará en el retardo q, mientras
que la PACF decae de manera exponencial o sinusoidal. Es decir, es un modelo de serie
temporal parsimonioso que se utiliza para dar cuenta de la autocorrelación a muy corto plazo.
\end{shaded}

Para ajustar un modelo MA(q) utilizamos la función \ti{Arima()} de R, indicándole el orden
c(0,0,1). El resultado mostrará la estimación de los parámetros del modelo: la/s pendiente/s
theta (indicada por ma1, ma2, ...), el intercepto (o media) y la varianza del ruido (sigma2).
También tenemos información sobre el error estándar de estas estimaciones, la verosimilitud
(Log Lik) y el coeficiente de información de Akaike del modelo (AIC).

Para predecir con este modelo utilizamos la función \ti{forecast()} de R indicándole el
horizonte de pronóstico con el argumento h.

\im{Identifica el modelo MA adecuado}

Analiza la serie austa del paquete fpp2 que contiene el número anual de visitantes
internacionales en Australia desde 1980 hasta 2015. Ajusta el modelo adecuado y realiza
predicciones para el próximo año.

Instrucciones

1. Accede a los datos, realiza los gráficos de la serie y correlogramas.

<<>>=
data(austa, package = "fpp2")
@

<<fig.width=7, fig.asp=0.7>>=
austa |> 
 as_tsibble(index = index) |> 
 gg_tsdisplay(austa, plot_type = "partial")
@


Según los resultados, ¿La serie es estacionaria? Si fuera necesario transformar la serie,
¿Qué tipo de transformación utilizarías?

\begin{shaded}
En el gráfico de la serie original debes observar si la serie es estacionaria, si existen
tendencias, estacionalidad o varianza no constante. Las series con tendencias se pueden
diferenciar para volverlas estacionarias. La diferenciación corresponde al parámetro d del
modelo ARIMA.
\end{shaded}

Según lo observado en los correlogramas ¿Qué tipo de modelo deberíamos ajustar a los datos
originales?

Recuerda cómo identificar un modelo AR o MA a partir de los correlogramas.

\begin{figure}[H]
\includegraphics[width = \linewidth]{ide}
\caption{¿Cómo identificar modelos AR y MA a partir de los correlogramas?}
   \label{fig:arma}
\end{figure}

2. Ajusta el modelo candidato

<<>>=
fit <- Arima(austa, order = c(0, 0, 1))
@

3. Finalmente grafica los pronósticos para el próximo año según el modelo elegido.

<<>>=
autoplot(austa) + autolayer(fitted(fit),series = "Fitted")
@


<<>>=
autoplot(forecast(fit, h = 12))
@


\subsection{Modelo ARMA}

Es hora de centrar nuestra atención en la combinación de los dos modelos anteriores. Cuando
juntamos los modelos AR y MA obtenemos un modelo autorregresivo de medias móviles ARMA(p,q),
donde las últimas p observaciones y los últimos q errores se usan como predictores en la
ecuación.

Un modelo autorregresivo de medias móviles ARMA(p,q) se puede pensar como una regresión donde
las últimas \emph{p} observaciones y los últimos \emph{q} errores se usan como predictores en
la ecuación.

Al ser una combinación de AR y MA, el modelo ARMA \textbf{intenta capturar 2 aspectos} al modelar series de tiempo:
 \begin{itemize}[itemsep=1ex]
  \item su propio comportamiento pasado como entradas para el modelo, el componente
  autorregresivo AR.
  \item la información del ruido o "errores" de una serie que se arrastra en el tiempo, el
  componente de medias móviles MA.
 \end{itemize}

NOTA: El modelo ARMA (p, q) es una combinación lineal de dos modelos lineales y, por lo
tanto, sigue siendo lineal en sí mismo.

Una de las características clave del modelo ARMA es que es parsimonioso y redundante en sus
parámetros. Es decir, un modelo ARMA a menudo requerirá menos parámetros que un modelo AR (p)
o MA (q) solo.

\im{Ejercicios}

Ahora que conoces varios modelos de series temporales, tienes una idea de cómo se comporta
cada uno y cuándo es útil.

Haz coincidir los siguientes gráficos con los modelos que hemos visto: modelos de ruido
blanco (WN), caminata aleatoria (RW), autorregresivo (AR), medias móviles (MA) y
autorregresivo de medias móviles (ARMA).

\begin{figure}[H]
\includegraphics[width = \linewidth]{ej1}
\caption{Identificar series}
   \label{fig:ej1}
\end{figure}

 \begin{itemize}[itemsep=1ex]
  
  \item Vemos que B y C son muy similares. Esto se debe a que RW es un caso especial de AR.
  
  \item Tanto en B como en C vemos \textbf{persistencia:} autocorrelaciones significativas
  para un gran número de rezagos.
  
  \item En B vemos que su ACF vuelve a cero más rápidamente que el de C. Esto es
  característico de un modelo AR.
  
  \item El PACF de un AR se corta en el retardo \emph{p}, esto lo vemos en B.
  \item El ACF cae de manera exponencial o sinusoidal para un modelo AR. Esto lo vemos en B
  \item El PACF de un modelo RW se corta en el retardo 1
  
  
  \item El ACF de un MA debe tener una autocorrelación que se corta en el retardo \emph{q},
  mientras que su PACF decae de manera exponencial o sinusoidal. Este es el caso de A.
  
  
  \item En ACF y PACF de WN deben tener una autocorrelación de aproximadamente cero en todos
  los retardos. Este es el caso de D
  
  
  \item Tanto el ACF como el PACF decaen para los modelos ARMA y la serie se comporta como
  una mezcla de MA y AR.
 \end{itemize}


\begin{shaded}
Recuerda que el modelo RW es un caso especial del AR. Ambos generalmente muestran
persistencia, pero el modelo AR vuelve a la media. Es decir, RW y AR generalmente muestran
una gran autocorrelación para muchos retardos (decaimiento), pero el ACF de un AR vuelve a
cero más rápidamente que el del RW. El PACF de un AR se corta en el retardo \emph{p},
mientras que el del RW se corta en 1 retardo. El modelo MA muestra una dependencia a muy
corto plazo, también vuelve a la media muy rápidamente. El ACF de MA debe tener una
autocorrelación que se corta en el retardo \emph{q}, mientras que su PACF decae. El modelo WN
no debe mostrar un patrón obvio, y por tanto el ACF y PACF de WN deben tener una
autocorrelación de aproximadamente cero en todos los retardos. Por último, tanto el ACF como
el PACF decaen para los modelos ARMA y la serie se comporta como una mezcla de MA y AR.
\end{shaded}


 \begin{itemize}[itemsep=1ex]
  \item (A) RW, (B) MA, (C) WN, (D) AR, (E) ARMA
  \item (A) MA, (B) AR, (C) RW, (D) WN, (E) ARMA
  \item \hl{(A) MA, (B) AR, (C) RW, (D) WN, (E) ARMA}
  \item (A) MA, (B) RW, (C) AR, (D) WN, (E) ARMA
 \end{itemize}


\begin{figure}[H]
\includegraphics{ej2}
\caption{Respuesta Correcta}
   \label{fig:rcorrecta}
\end{figure}


\section{ARIMA}

Los modelos ARMA (los AR y los MA) solo pueden funcionar con datos estacionarios, sin
embargo, la gran mayoría de los datos del mundo real no son estacionarios. En estos casos
necesitaremos primero diferenciar la serie de datos para estacionarizarla. Esto nos lleva a
los \textbf{modelos ARIMA que significa un modelo ARMA integrado (integrar es lo opuesto a
diferenciar).}


<<>>=
data(usnetelec, package = "expsmooth")
@

<<fig.width=7, fig.asp=0.7>>=
ggtsdisplay(usnetelec)
@

Vemos una tendencia creciente, por lo cual la serie no es estacionaria y por lo tanto sería
necesario diferenciarla.

<<>>=
(fit <- auto.arima(usnetelec))
@

\begin{shaded}
Vemos que los datos se han diferenciado una vez y luego en el primer dos para el orden
\emph{p} de la parte autorregresiva nos dice que se han utilizado dos observaciones pasadas y
en el orden \emph{q} para la parte de medias móviles indica que se han utilizado dos errores
pasados en la ecuación. Cuando tomamos diferencias en la series el coeficiente C se suele
llamar deriva (\emph{drift}), por eso se ve ahora en el resultado una columna con este
término.
\end{shaded}

Para ahorrar tiempo puedes probar tu mismo algunos modelos o seleccionar la opción
\ti{trace = TRUE} para ver una lista de los modelos posibles, junto con su valor de AIC.

<<>>=
auto.arima(usnetelec, trace = TRUE)
@

\im{Ejercicios}

Muchos de los modelos de series temporales que discutimos hasta ahora pueden explicarse
fácilmente mediante el modelo ARIMA. Indica a continuación cómo formularías los siguientes
modelos:

 \begin{enumerate}[letras]
   \item Ruido blanco (WN)
   \item Caminata aleatoria (RW)
   \item Autorregresivo (AR)
   \item De media móvil (MA)
 \end{enumerate}

  \begin{enumerate}[numeros]
   \item ARIMA (p, 0, 0)
   \item ARIMA (0, 0, 0)
   \item ARIMA (0, 0, q)
   \item ARIMA (0, 1, 0)
 \end{enumerate}

Respuesta \hl{A-2, B-4, C-1, D-3}

Recuerda que el modelo ARIMA tiene argumentos p (orden del componente autorregresivo), d
(diferenciación -primeras diferencias- de la serie) y q (orden del componente de media
móvil): ARIMA(p,d,q).

\im{Ejercicios}

Vamos a encontrar un modelo ARIMA para los datos de usuarios conectados de un servidor de
internet registrados cada minuto durante 100 minutos. Los datos internet se encuentran en el
paquete fma.

<<>>=
i <- fma::internet
@

1. Grafica la serie junto con sus correlogramas

<<fig.width=7, fig.asp=0.7>>=
ggtsdisplay(i)
@

¿Qué observas? ¿la serie es estacionaria? 

\begin{shaded}
La serie no es estacionaria. 
\end{shaded}

Si fuera necesario, ¿qué transformación utilizarías para estacionarizarla?. 

\begin{shaded}
Aplicaría una primera diferencia.
\end{shaded}

Según el ACF y PACF, ¿qué tipo de modelo ARIMA ajustarías a los datos?

\begin{shaded}
Vemos \textbf{persistencia} en el ACF
\end{shaded}


Encuentra un modelo ARIMA adecuado para el conjunto de datos internet y guardarlo en un
objeto llamado fit1.

<<>>=
(fit_1 <- auto.arima(i, trace = TRUE))
@

¿Qué modelo es seleccionado? ¿Se corresponde a lo que habías observado en los gráficos
anteriores?

\begin{shaded}
No, no se corresponde.
\end{shaded}

Modifica los argumentos de la función de ajuste para obtener mayor flexibilidad en la
búsqueda de modelos.

<<>>=
(fit_2 <- auto.arima(i, stepwise = FALSE, trace = FALSE))
@

¿Qué modelo es seleccionado? ¿Es mejor que el modelo anterior? ¿por qué?

\begin{shaded}
No, no es mejor que el modelo anterior porque requiere un modelo autorregresivo de orden 3.
\end{shaded}

Finalmente, grafica los pronósticos para la próxima media hora. Establece el argumento h en
consecuencia.

<<>>=
autoplot(forecast(fit_2, h = 30))
@

\section{SARIMA}

Modelos automáticos ARIMA para series temporales estacionales
Como vimos en el video, la función auto.arima() también funciona con datos estacionales. 

En este ejercicio, utilizarás esta función para modelar y pronosticar los datos h02 del
paquete fpp2, que contienen información sobre las ventas mensuales de medicamentos con
corticosteroides en Australia.

La salida corresponderá a los parámetros (p, d, q)(P, D, Q)[m]

\im{Instrucciones}

 \begin{enumerate}[numeros]
   \item Comienza con un gráfico de los datos h02 para verificar que tenga una varianza
   estable.
   \item Ajusta un modelo ARIMA estacional con lambda = 0. Guarda el resultado en un objeto
   fit.
   \item Interpreta los resultados. ¿Qué niveles de diferenciación se usaron en el modelo?
   ¿Cuál es el número de primeras diferencias d y cuál el número de diferencias estacionales
   D?
   \item Grafica los pronósticos para los próximos 2 años utilizando el modelo ajustado.
   Selecciona h en consecuencia.
 \end{enumerate}

<<>>=
h <- fpp2::h02
@

<<fig.width=7, fig.asp=0.7>>=
ggtsdisplay(h)
@

<<>>=
(fit <- auto.arima(h))
@

La parte no estacional del modelo incluye una diferenciación (primeras diferencias) de la
serie, un componente autorregresivo de orden 4, y un componente de medias móviles de orden 1.

La parte estacional del modelo incluye una diferenciación estacional de la serie y un
componente de medias móviles estacional de orden 2.

Los datos son mensuales, por lo cual m=12.

\begin{shaded}
Se ve una primer diferencia en el parámetro \emph{d}.  Con 2 retardos AR y 1 errores con
retardo para las medias móviles. Se ven que hay una diferencia estacional $D$ y 2 errores
con retardo estacional MA. El número de observaciones es de 12
\end{shaded}

<<fig.width=7, fig.asp=0.7>>=
autoplot(forecast(fit, h = 24))
@

Observamos cómo las partes estacionales del modelo parece que han capturado bastante bien la
estacionalidad.

\section{Diagnóstico}

Una forma de verificar si nuestro modelo es bueno es tratar de predecir lo que ya hemos visto
y verificar que capturamos toda la información de los datos, que no cometemos demasiados
errores.

Para diagnosticar un modelo y evaluar si tiene sentido realizar predicciones con él, es
importante verificar siempre que los residuos se comporten bien (es decir, que no tengan
valores atípicos o patrones) y que se parezcan al ruido blanco:


 \begin{itemize}[itemsep=1ex]
  \item no correlacionado
  \item centrado en media cero
 \end{itemize}

Además, los intervalos de predicción se calculan suponiendo que los residuos:

 \begin{itemize}[itemsep=1ex]
  \item tienen varianza constante
  \item y distribución normal
 \end{itemize}

Una función conveniente para usar para verificar estos supuestos es la \ti{checkresiduals()}.
Esta función produce un gráfico de tiempo, un gráfico de ACF, un histograma y una prueba de
Ljung-Box en los residuos.

<<>>=
(fit_good <- auto.arima(lh))
@

<<fig.width=7, fig.asp=0.7>>=
checkresiduals(fit_good)
@

\begin{shaded}
En este ejemplo la prueba muestra un p-valor por encima del umbral del 0.05 con lo cual
decimos que los residuos son independientes, es decir, no muestran autocorrelación, se parece
a lo que cabría de esperar del ruido blanco. Esto también se confirma mirando la función de
autocorrelación y además el histograma se ve bastante cercano a la curva normal, aunque
posiblemente haya algo de asimetría y algún valor atípico en el lado derecho de la
distribución.
\end{shaded}

Recuerda entonces: \textbf{debes verificar tus residuos antes de realizar predicciones con
tu modelo} 

1. La normalidad de los residuos facilita el cálculo de los intervalos de predicción, pero no
es esencial. 2. Los pequeños residuos pueden ser una señal de que los datos de entrenamiento
se han sobreajustado. 3. Un buen ajuste implica que los residuos no estén correlacionados,
estén centrados en media cero y (es deseable) que tengan varianza constante.

\section{Predicción}

Las predicciones son útiles en muchas situaciones para una planificación efectiva y
eficiente, cualesquiera que sean las circunstancias o los horizontes de tiempo involucrados.
Podemos necesitar calcular pronósticos con varios años de anticipación (para el caso de
inversiones de capital), o solo unos minutos antes (en telecomunicaciones).

Aunque hemos calculado predicciones con los modelos ARIMA en ejemplos anteriores, aún no
hemos explicado cómo se obtienen. En este vídeo discutiremos qué son las predicciones, los
intervalos de predicción, errores de predicción, la precisión y el sesgo.


Hemos discutido algunos conceptos claves sobre las predicciones y los intervalos de
predicción:

 \begin{itemize}[itemsep=1ex]
  \item La predicción de un modelo es la media (o la mediana) de los posibles valores futuros
  para esta serie.
  \item Los intervalos de predicción que son los percentiles de estos posibles valores
  futuros.
 \end{itemize}

Por defecto se calculan los intervalos de predicción al 80\% (la región azul oscura sombreada)
y 95\% de confianza (la región celeste sombreada).

Un modelo que ajusta bien a tus datos no necesariamente hará buenos pronósticos,
\textbf{debemos verificar el rendimiento de la predicción en un nuevo conjunto de datos.}
Llamamos:

 \begin{itemize}[itemsep=1ex]
  \item Las observaciones utilizadas para construir sus pronósticos se llaman conjunto de
  entrenamiento. 
  \item Las observaciones ocultas restantes forman el conjunto de prueba, y se utilizan
  verificar la calidad de las predicciones.
 \end{itemize}

Calculamos la precisión de nuestro método utilizando los errores de predicción (las
diferencias entre las observaciones del conjunto de datos de prueba y los pronósticos
puntuales).

Los errores de predicción se diferencian de los residuos (las diferencias entre las
observaciones del conjunto de datos de entrenamiento y los pronósticos puntuales).

Discutimos las diferencias entre la precisión y el sesgo de una predicción.

\section{Precisión de la predicción}

\im{Criterios de evaluación de modelos de serie temporal}

  \begin{enumerate}[numeros]
   \item \textbf{Evaluación del modelo basado en la precisión de sus predicciones:} Divide tu
   conjunto de datos en 2, construyes el modelo con uno de ellos, luego predices los
   resultados con el resto del conjunto de datos y calculas la diferencia entre lo observado
   y lo predicho por el modelo. El modelo con menor error será considerado como un mejor
   modelo predictivo. Finalmente podrías realizar validación cruzada considerando múltiples
   particiones de los datos.
   \item \textbf{Evaluación del modelo basado en su bondad de ajuste:} Puedes comparar
   modelos mediante alguna métrica de "performance" (e.g. AIC, AICc o BIC). Lo que realizas
   básicamente es controlar si al agregar nuevos términos al modelo mejora.
 \end{enumerate}

Hay varias formas de \textbf{medir la precisión de una predicción:}

 \begin{itemize}[itemsep=1ex]
  \item podemos tomar el promedio de los errores en valor absoluto, o error absoluto medio
  (\textbf{MAE}). Se toma el valor absoluto para que los errores positivos y negativos no se
  cancelen.
  \item El promedio de los errores al cuadrado, o error cuadrático medio \textbf{MSE}. 
  \item O su raíz cuadrada que es el estadístico \textbf{RMSE}. Al elevar las diferencias al
  cuadrado los errores positivos y negativos no se cancelan.
  \item El promedio del error absoluto en porcentaje, o \textbf{MAPE}
  \item O escalar el error absoluto promedio, para obtener el \textbf{MASE}
 \end{itemize}

En todos los casos un valor pequeño indica una mejor predicción.

La función \ti{accuracy()} calcula todas estas medidas y más.

Recuerda que en la mayoría de los casos estaremos interesados en las medidas de error del
conjunto de prueba, que se basan en el \textbf{error de predicción}. Las medidas de error del
conjunto de entrenamiento se basan en los \textbf{residuos}.

\im{Recuerde}

\begin{shaded}
La normalidad de los residuos facilita el cálculo de los intervalos de predicción, pero no es
esencial. 2. Los pequeños residuos pueden ser una señal de que los datos de entrenamiento se
han sobreajustado. 3. Hacer un modelo más complicado a veces puede ser útil, pero puede
empeorar las predicciones.
\end{shaded}

\im{Pros y contras de las medidas de precisión de la predicción}

La medición de la precisión de la predicción (o su error) no es una tarea fácil ya que no hay
un único indicador útil para todos los problemas.

Primero recuerda las medidas de precisión de la predicción que hemos visto en el vídeo
anterior.

\begin{figure}[H]
\includegraphics[width = \linewidth]{accuracy}
\caption{Medidas de precisión}
   \label{fig:precision}
\end{figure}

En esta entrada veremos pros y contras de las medidas de precisión de la predicción para que
puedas seleccionar la más adecuada para resolver tu problema

 \begin{itemize}[itemsep=1ex]
 
  \item Los valores de MAE o RMSE expresan el error de la predicción del modelo en las
  unidades de la variable de interés (la respuesta) y por tanto son sencillos de interpretar.
  Ten en cuenta que entonces sus valores dependen de la escala de los datos, y pueden variar
  de 0 a $\infty$ , son indiferentes a la dirección de los errores y son insensible a
  desviaciones constantes o proporcionales.
  
  \item El resultado RMSE siempre será mayor o igual al MAE, y dependerá del tamaño de la
  muestra. RMSE tiende a ser cada vez más grande que MAE a medida que aumenta el tamaño de la
  muestra de prueba. Por ello, debemos tener cuidado al comparar los valores de RMSE en
  muestras de distinto tamaño.
  
  \item MSE es muy sensibles a los valores extremos, porque al tomar los errores al
  cuadrados, otorgan un peso relativamente alto a los grandes errores, es decir, puede ser
  más útil cuando no deseamos obtener grandes errores. RMSE tiene la ventaja de penalizar los
  errores grandes más, por lo que puede ser más apropiado en algunos casos.
  
  \item Los errores porcentuales MAPE tienen la ventaja de estar libres de unidades y, por lo
  tanto, se usan con frecuencia para comparar los rendimientos de predicción entre conjuntos
  de datos. Sin embargo, solo sirve si nuestros datos son todos positivos y no contienen
  muchos ceros o valores pequeños. Esto es debido a que MAPE divide el error absoluto entre
  los datos reales, los valores que se aproximan a 0 pueden aumentar significativamente el
  MAPE. MAPE también supone que hay un cero natural, por lo que no se puede usar con la
  temperatura.
  
  \item Los errores de escala MASE fueron propuestos por Hyndman y Koehler (2006) como una
  alternativa al uso de errores porcentuales al comparar la precisión de la predicción entre
  series con diferentes unidades. Es como MAE pero está escalado para que pueda compararse
  ente series.
  
  \item El cociente entre el RMSE y el MAE permite determinar hasta qué punto la existencia
  de valores extremos está afectando al modelo.
  
 \end{itemize}

\im{Optimización}

 \begin{itemize}[itemsep=1ex]
  \item la optimización de MSE tiene como objetivo producir una predicción que sea correcta
  en promedio y, por lo tanto, imparcial.
  
  \item para optimizar MAE, la predicción debe ser tantas veces mayor que el valor de la
  serie como menor. En otras palabras, estamos buscando un valor que divida nuestro conjunto
  de datos en dos partes iguales. Esta es la definición exacta de la mediana.
  
  \item la optimización de RMSE buscará ser correcta en promedio
  
  \item Por lo tanto la diferencia entre MAE y RMSE es que el primero apunta a la mediana, y
  el segundo apunta a la media. MAE brinda protección contra los valores atípicos, mientras
  que RMSE brinda la seguridad de obtener un pronóstico imparcial.
  
  \item MAPE promueve un pronóstico muy bajo, ya que asigna una gran importancia a los
  errores de pronóstico cuando los valores de la serie son bajos
  
 \end{itemize}
 
Cada técnica tiene algunos beneficios y algunos riesgos, como veremos en las páginas
siguientes. Solo la experimentación revelará qué técnica funciona mejor para un conjunto de
datos.

\im{Validación del modelo}

La semana pasada comparamos 3 modelos de series temporales (AR(1), AR(2) y AR(3)) para los
datos anuales de manchas solares (sunspot.year) desde 1700 a 1988 según los coeficientes AIC,
AICc y BIC.

Divide los datos en un conjunto de entrenamiento y otro de prueba y compara los modelos según
su capacidad predictiva e indica cuál de las siguientes afirmaciones es VERDADERA.

\im{Instrucciones}

1. Crea los conjuntos de entrenamiento y prueba.

Los datos sunspot.year vienen precargados en R. Primero vemos el número de datos que tenemos
para decidir cuántas observaciones destinar a cada conjunto de datos.

<<>>=
length(sunspot.year)
@

Tenemos 289 observaciones. Usualmente se destina el 80\% de las observaciones al conjunto de
entrenamiento y el 20\% restante al de prueba, con lo cual utilizaremos las primeras 232
observaciones para el conjunto de entrenamiento.

Sustituye los siguientes espacios en blanco por las funciones y argumentos adecuados para crear los conjuntos de entrenamiento y prueba.

<<>>=
train <- subset(sunspot.year, end = 232)
test <- subset(sunspot.year, start = 232)
@

<<fig.width=7, fig.asp=0.6>>=
autoplot(train) + autolayer(test)
@


2. Ajusta los 3 modelos candidatos sobre el conjunto de datos adecuado.

<<>>=
fit1 <- Arima(train, order = c(1, 0, 0)) # modelo AR(1)
fit2 <- Arima(train, order = c(2, 0, 0)) # modelo AR(1)
fit3 <- Arima(train, order = c(3, 0, 0)) # modelo AR(1)
@

3. Evalúa la precisión de las predicciones de cada modelo sobre el conjunto de datos
adecuado.

<<>>=
accuracy(forecast(fit1), test)
accuracy(forecast(fit2), test)
accuracy(forecast(fit3), test)
@

\hl{El modelo que mejor predice nuestra serie es AR(3)}

\section{Validación Cruzada}

Para ver qué tan bien predice un modelo no podemos guiarnos por el diagnóstico del ajuste del
modelo ya que es fácil sobreajustar los datos  incluyendo más términos en el modelo. Las
predicciones del modelo sobre nuevos datos generalmente empeorarán a medida que se agreguen
términos de orden superior en el modelo.

La validación cruzada (CV) de series temporales permite medir el rendimiento predictivo del
modelo para un gran número de conjuntos de datos de entrenamiento y prueba.

Con la función \ti{tsCV()} de R, podemos calcular:

 \begin{itemize}[itemsep=1ex]
  \item Pronósticos de un solo paso.
  \item Pronósticos de varios pasos hacia adelante.
 \end{itemize}

Así, por ejemplo, podemos evaluar los modelos mediante el error cuadrático medio para
diferentes horizontes de pronóstico basado en la CV de series de tiempo.


\im{Realiza una validación cruzada para el siguiente modelo}

La función \ti{tsCV()} calcula los errores de validación cruzada de series temporales. 

Aquí vas a analizar los datos goog mediante validación cruzada con los siguientes pasos:

Usando los datos goog y la función de predicción naive(), calcula los errores obtenidos con
validación cruzada hasta 8 pasos por delante.

Calcula los errores por validación cruzada hasta 8 pasos hacia adelante

<<>>=
goog <- fpp2::goog
@

debes especificar la serie temporal (y), el método de pronóstico (forecastfunction) y el
horizonte de pronóstico (h). 

<<>>=
goog_ts <- fpp2::goog |> as_tsibble()
@


<<>>=
goog_tr <- goog_ts |> stretch_tsibble(.init = 800, .step = 1)
@


<<>>=
fc <- goog_tr |> 
    model(NAIVE(value)) |> 
    forecast(h = 8) |> 
    group_by(.id) |> 
    mutate(h = row_number()) |> 
    ungroup() |> 
    as_fable(response = "value", distribution = value)
@


<<>>=
fc_tb <- fc %>%
    accuracy(goog_ts, by = c("h", ".model")) %>%
    mutate(MSE = RMSE^2) |> 
    select(h, .model, RMSE, MSE)
@

<<>>=
fc_tb |> 
    ggplot(aes(x = h, y = MSE)) +
    geom_point()
@

\section{Procedimiento General}

  \begin{enumerate}[numeros]
    \item Grafica los datos
  	\item Grafica el ACF/PACF
  	\item Ajusta un modelo ARIMA
  	\item Diagnostica el modelo
  	\item Predice en un nuevo conjunto de prueba.
  	\item Evalúa la precisión de las predicciones.
 \end{enumerate}

\subsection{Paso 1: Graficar}

Grafica los datos e identifica cualquier observación inusual. Comprenda los patrones y si es
necesario, transforma los datos (usando una transformación logarítmica por ejemplo) para
estabilizar la varianza.

Cantidad de hormona luteinizante en muestras de sange tomadas  cada 10 minutos.

<<fig.width=6.29, fig.asp=0.6>>=
autoplot(lh)
@

Vemos en general que no hay datos demasiados inusuales y de que el comportamiento es
bastante estacionario con lo cual podemos continuar.

\subsection{Paso 2: Grafica el ACF/PACF}

¿Qué tipo de modelo ARIMA puede ser apropiado?

<<fig.width=6.29, fig.asp=0.6>>=
ggtsdisplay(lh)
@

\begin{shaded}
En este caso como ambas funciones se cortan a retardos muy bajos, no nos permitiría detectar
el orden del modelo. Vamos a ajustar entonces un modelo automático ARIMA.
\end{shaded}

\subsection{Paso 3: Ajusta un modelo ARIMA}

Primero debemos dividir los datos en un conjunto de entrenamiento y en un conjunto de
prueba, así podemos evaluar la calidad de nuestras predicciones.  Para ello veamos el largo
de la serie:

<<>>=
length(lh)
@

Entonces como vemos pocas observaciones vamos a tomar un conjunto de entrenamiento con las
primeras 40 y el conjunto de prueba con las siguientes 8

<<>>=
lh_train <- subset(lh, end = 40)
lh_test <- subset(lh, start = 41)
@

Ahora ajustamos varios modelos ARIMA y automáticamente la función \ti{auto.arima}
seleccionará el mejor mediante el coeficiente AICc. Puedes seleccionar el modelo por ti
mismo o utilizar un algoritmo automatizado para ello.

<<>>=
(fit <- auto.arima(lh_train))
@

\begin{shaded}
Obtenemos un modelo propuesto de medias móviles de orden 2 (MA(2))
\end{shaded}

\subsection{Paso 4: Diagnóstico}

Verificar que los residuos del modelo elegido sean ruido blanco.

<<fig.width=6.29, fig.asp=0.7>>=
checkresiduals(fit)
@

\begin{shaded}
Vemos que los residuos
\end{shaded}

# TODO: ME QUEDE EN EL PASO 4 MINUTO 2:09












































