\chapter{Marco Teórico}

<<>>=
graficar <- function(.df, vector, .brk) {
 .df |> 
  ggplot(aes(x = date, y = {{ vector }})) +
  geom_line() +
  geom_smooth(method = "loess", formula = 'y ~ x', se = F, size = 0.5) +
  facet_grid(rows = vars({{ .brk }}), scales = "free_y") +
  scale_x_date(date_breaks = "6 month", labels = date_format("%Y-%b")) +
  drako
}
@

<<>>=
agregar_info <- function(gg_object) {
 gg_object +
  stat_peaks(geom = "point",   span = 11, color = "red",  size = 0.7) +
  stat_valleys(geom = "point", span = 11, color = "blue", size = 0.7) +
  stat_peaks(geom        = "text",
             span        = 11,
             color       = "red",
             vjust       = 0,
             hjust       = -0.5,
             x.label.fmt = "%b",
             size = 1.5) +
  stat_valleys(geom        = "text",
               span        = 11,
               color       = "blue",
               vjust       = 0,
               hjust       = -1,
               x.label.fmt = "%b",
               size = 1.5)
}
@


\section{Estacionalidad}

El componente estacional consiste en efectos que son razonablemente estables con respecto al
tiempo, la dirección y la magnitud. Surge de influencias sistemáticas relacionadas con el
calendario.

También incluye efectos sistemáticos relacionados con el calendario que no son estables en su
calendario anual o que son causados por variaciones en el calendario de un año a otro, tales
como: la Navidad, el inicio y fin del curso escolar, el número de días por mes, las
vacaciones y días festivos que ocurren cada año pero pueden variar en el calendario.

\im{¿Cómo identificamos la estacionalidad?}
 
La estacionalidad en una serie temporal puede identificarse mediante picos y valles
regularmente espaciados que tienen una dirección constante y aproximadamente la misma
magnitud cada año, en relación con la tendencia.
 
\im{¿Qué es el ajuste estacional y por qué lo necesitamos?}

El ajuste estacional es el proceso de estimar y luego eliminar de una serie de tiempo las
influencias que son sistemáticas y relacionadas con el calendario. Los datos observados deben
ajustarse estacionalmente ya que los efectos estacionales pueden ocultar tanto el verdadero
movimiento subyacente en la serie, como ciertas características no estacionales que pueden
ser de interés para los analistas.
 
\im{Manchas solares}

A continuación, agrega las órdenes necesarias para generar un gráfico de la serie de tiempo y
un gráfico de la ACF (correlograma) para los datos sunspot.year que vienen precargados en R.

Recuerda que la ciclicidad induce picos en la duración promedio del ciclo. 

<<>>=
autoplot(sunspot.year)
ggAcf(sunspot.year)
@

Al observar el gráfico ACF mira cómo cambian las correlaciones a medida que aumenta el
retraso, ¿en qué valor de retraso puedes encontrar la autocorrelación máxima? ¿puedes ver
alguna estacionalidad, ciclicidad y/o tendencia? ¿Qué comportamiento puedes identificar?

\begin{shaded}
Primero, vemos en la gráfica que la serie tiene patrones \textbf{cíclicos}. Recordemos que
un ciclo ocurre cuando los datos exhiben subidas y bajadas que no tienen una frecuencia fija.
Estas fluctuaciones generalmente se deben a las condiciones económicas y, a menudo, están
relacionadas con el "ciclo económico". La duración de estas fluctuaciones suele ser de al
menos 2 años. La serie anual de manchas solares sigue un ciclo de aproximadamente 10-11 años,
esto causa un pico en el retardo o LAG 10-11 en el gráfico de autocorrelación ACF.
\end{shaded}


\im{Muertes accidentales en EE.UU}

La estacionalidad induce picos en los \textbf{retardos estacionales}. Piensa en las
vacaciones, cada día festivo tendrá ciertos productos que alcanzan su punto máximo en ese
momento cada año y, por lo tanto, la correlación más fuerte será los valores en ese mismo
momento cada año.

Utiliza los datos USAccDeaths (precargados en R) sobre mortalidad mensual por accidentes en
EE.UU. en 1973–1978 y detecta cuál es la estacionalidad de los datos. Para ello, rellena los
espacios a continuación y ejecuta las órdenes en R.
 

<<>>=
autoplot(USAccDeaths)
ggAcf(USAccDeaths)
@
 
¿Qué estacionalidad tienen los datos?

\begin{shaded}
Observamos un comportamiento estacional cada 6 meses, esto causa un pico en el retardo o LAG
6 en el correlograma.
\end{shaded}


\subsection{Identificar ACF}

Recuerda que el gráficos de autocorrelación ACF nos ayuda a identificar las características
de las series temporales.

Con esto en mente, observa los siguientes gráficos y haz coincidir los gráficos ACF que se
muestran (A-C) con sus gráficos de tiempo correspondientes (1-3).


\begin{figure}[H]
\includegraphics[width = \linewidth]{ts_acf}
\caption{Interpretación de resultados}
   \label{fig:iden}
\end{figure}

\begin{shaded}
1-B, 2-A y 3-C
\end{shaded}


\section{Estacionariedad}

\im{¿Qué es una serie estacionaria?}

En general, se dice que una serie temporal es estacionaria cuando es "estable", es decir,
cuando se comporta de manera similar de un período de tiempo a otro y sus propiedades no
dependen del momento en que se observa la serie.

En el contexto de series temporales, la estacionariedad se refiere a: la estabilidad de la
media (es decir, a que no haya una tendencia) y la estabilidad de la correlación (es decir,
la estructura de correlación de los datos permanece constante en el tiempo).

Entonces, tenemos los siguientes casos:

 \begin{itemize}[itemsep=1ex]
  \item \textbf{Serie estacionaria:} si los datos varían alrededor un mismo valor promedio y
  con la misma variabilidad.
  \item \textbf{Serie no estacionaria:} si la media y/o la varianza cambian a lo largo del
  tiempo.
 \end{itemize}
 
\im{¿Por qué nos interesa que la serie sea estacionaria?} 

Cuando una serie temporal es estacionaria, puede ser más fácil modelarla. 


Los métodos de modelado estadístico suponen o requieren que las series temporales sean
estacionarias para ser efectivos.

A grandes rasgos verificar esta propiedad en el estudio de las series de tiempo tiene su
importancia en los siguientes aspectos.

 \begin{itemize}[itemsep=1ex]
  \item \textbf{Facilidad de Análisis:} las series estacionarios pueden modelarse con pocos
  parámetros.
  \item \textbf{Mejor Entendimiento:} las series temporales tienen distribución estable en el
  tiempo, es decir, las características estadísticas de nuestra serie de tiempo (media,
  varianza y autocorrelación) serán las mismas tanto en el futuro como en el pasado.
  \item \textbf{Ubicuidad:} la estacionariedad nos permite generalizar nuestros resultados al
  campo de estudio, no sólo limitarnos al problema que estemos analizando.
 \end{itemize}
 
En el caso de que se incumpla el supuesto de estacionariedad, debemos estacionarizar las
series de tiempo antes de ajustar un modelo. Veremos más adelante cómo hacerlo.

\im{¿Cómo identificar si una serie es estacionaria?}

Podemos evaluar la estacionariedad mediante gráficos y/o pruebas estadísticas. Si la serie es
estacionaria, los gráficos de tiempo mostrarán que la serie es aproximadamente horizontal
(aunque es posible algún comportamiento cíclico), con una variación constante (sin tendencia
ni estacionalidad). Para una serie temporal estacionaria, además el gráfico de
autocorrelación ACF caerá a cero relativamente rápido, mientras que la ACF de datos no
estacionarios disminuye lentamente.

Para evaluar la estacionariedad en conjuntos de datos donde las tendencias y las
estacionalidades son difíciles de ver, puede ser bastante útil evaluar la autocorrelación de
la serie temporal. Podemos entonces observar el correlograma de la serie temporal para
evaluar su estacionariedad.


\section{Autocorrelación}

La esencia de la \textbf{correlación serial (autocorrelación)} es que deseamos ver cómo se
afectan entre sí las observaciones secuenciales en una serie temporal. Si podemos encontrar
patrones (estructura) en estas observaciones, entonces probablemente nos ayudará a mejorar
nuestros modelos y predicciones.

Algunos \textbf{patrones que hemos detectado en el correlograma} se pueden resumir a
continuación:


 \begin{itemize}[itemsep=1ex]
 
  \item Las tendencias fuertes darán lugar a que las observaciones más recientes tengan un
  valor más cercano entre sí. El gráfico ACF de las series temporales con \textbf{tendencia}
  tiende a tener valores positivos en los primeros retardos que disminuyen lentamente a
  medida que aumentan los retardos.
  
  \item Cuando la serie es \textbf{estacional}, en el gráfico ACF las autocorrelaciones serán
  mayores en los retardos estacionales (es decir, en múltiplos de la frecuencia estacional).
  Piensa en las vacaciones, cada día festivo tendrá ciertos productos que alcanzan su punto
  máximo de venta en ese momento cada año y, por lo tanto, la correlación más fuerte será los
  valores en ese mismo momento cada año.
  
  \item Cuando los datos tienen \textbf{tendencia y estacionalidad}, observamos una
  combinación de los dos efectos anteriores.
  
  \item De manera similar a lo que ocurre con la estacionalidad, cuando la serie es
  \textbf{cíclica}, veremos que en el gráfico ACF las autocorrelaciones serán mayores en la
  duración promedio del ciclo.
  
 \end{itemize}


\im{Terminología}

 \begin{itemize}[itemsep=1ex]
  
  \item La autocorrelación también se llama \textbf{correlación en serie}. Este tipo de
  correlación se utiliza para comprender cómo las observaciones de series temporales dependen
  de los valores de la misma serie en momentos anteriores.
  
  \item Las observaciones pasadas de la serie se denominan retrasos o retardos o lag.
  
  \item Un proceso es \textbf{ergódico} cuando conforme k se hace más grande, la
  autocorrelación se hace más pequeña. Es decir, que la dependencia entre variables tiene
  menos importancia pasado más tiempo.
  
 \end{itemize}

\section{Transformaciones}

Hemos visto qué es la estacionariedad y las ventajas que presentan las series estacionarias
cuando queremos modelar y predecir. Sin embargo, \textbf{las series temporales generalmente
no son estacionarias.}

\im{¿Cómo hacer una serie temporal estacionaria?}

A menos que tu serie temporal sea estacionaria, no puedes construir un modelo de serie
temporal. Esta es la razón por la que estudiamos la estacionariedad antes de hablar de
modelos de series temporales.

Las series temporales con tendencias, o con estacionalidad, no son estacionarias: la
tendencia y la estacionalidad afectarán el valor de la serie temporal en diferentes momentos.

En los casos en que se incumple el supuesto de estacionariedad, el primer requisito es
estacionarizar la serie de tiempo. Hay múltiples formas de hacer que tus datos sean
estacionarios. Por ejemplo, podemos transformar la serie tomando diferencias (anuales o
estacionales) y logaritmos para estacionarizar una serie temporal.

Cuando se aplican tanto las diferencias estacionales como las diferencias regulares (o
diferencias primeras), no importa qué se haga primero: el resultado será el mismo. Sin
embargo, si los datos tienen un patrón estacional fuerte, \textbf{recomendamos que la
diferenciación estacional se haga primero}, porque la serie resultante a veces será
estacionaria y no habrá necesidad de una primera diferencia adicional. Si primero se hace la
diferenciación, todavía habrá presente estacionalidad.

\im{Diferencia estacional}

Una forma de \textbf{desestacionalizar} es tomar una \textbf{diferencia estacional}. Es
decir, podemos calcular la diferencia entre el valor de la serie en un mes del año respecto
al mismo mes del año anterior. Recuerda que siempre se pierde el primer dato de la serie en
la diferenciación.

\begin{center}
\ti{diff(x, lag = 1, differences = 1, ...)}
\end{center}

La función diff() permite especificar el retardo (lag) y el orden (differences) de las
diferencias. El argumento lag especifica si tomamos diferencias en 1 tiempo o más (por
defecto es 1), mientras que el argumento differences refiere a si tomamos diferencias anuales
(1), mensuales (12), etc..

\im{Cálculo de la tasa de cambio de la serie}

\begin{center}
\textbf{Primera diferencia del logaritmo = cambio porcentual}
\end{center}

Cuando aplicamos el logaritmo junto con la diferenciación de la serie pasamos de tener
diferencias absolutas a obtener diferencias relativas (es decir, porcentajes). Por tanto, la
serie diff(log(x)) representa el cambio porcentual en "x" de un período a otro.

Esto es porque el cambio porcentual en "x" en el período "t", definido como (X(t) -X(t-1)) /
X(t-1), es aproximadamente igual a log(X(t)) - log(X(t-1)), cuando el cambio porcentual
es pequeño. En términos estadísticos, esto significa que es virtualmente idéntico a diff(
log(x)).

Esta transformación nos permite comparar "manzanas con manzanas" entre acciones, índices o
cualquier otra serie.


\section{Caso de Uso}

Para poder ver como los conceptos se van aplicando, consideremos un caso de uso en el que
analizaremos las series de tiempo de dos materiales que se utilizan con frecuencia en PLEX.
El objetivo final es probar varios modelos y realizar un pronóstico de consumo para un
horizonte adecuado. Las preguntas de investigación estarán relacionados a la presencia de
valores atípicos y la cantidad de datos necesaria para poder realizar un buen pronóstico. 
También es importante destacar que el consumo de estos materiales se divide en dos grandes
rubros, los cuales son el mantenimiento preventivo y el correctivo.  Una interrogante será
si las series deben pronosticarse por separado en vista de que es posible de que los procesos
implícitos que generan cada serie son diferentes.

El primer paso es conectarnos a nuestra base de datos para extraer la tabla donde se
almacenan los datos históricos de consumo.

<<>>=
con <- conectar_msql()
@

Debido a que hay muchos códigos que se utilizan para identificar un mismo tipo de material,
será necesario realizar una preparación.  Comencemos definiendo algunos parámetros para
poder descargar solo el material necesario, delegando de esta forma al servidor la tarea de
realizar la consulta y entregarnos lo que necesitamos.

<<>>=
materiales_criticos <- c("OSP0001440",  # MUFA PARA FIBRA 48 COLOR AZUL
                         "OSP0000111",  # FIBER OPTIC CABLE ADSS FOR 150 METER
                         "OSP0001313",  # FIBER OPTIC CABLE ADSS FOR 150 METER GAPS 48 HILOS
                         "OSP0000193",  # MUFA PARA FIBRA 48 HILOS VERTICAL     
                         "ACC005283")	 # MUFA ONE
@

Para cada tipo de material, hay dos tipos de consumo:

<<>>=
tipos_mantenimiento <- c(correctivo = "correctivo", preventivo = "preventivo")
@

Creemos una lista que nos permita acortar los nombres informales de los materiales:

<<>>=
mk <- c("Mufa 48 Hilos"           = "mufa48",
        "Fibra 48 Hilos vano 150" = "fibra48",
        "Bandejas Mufa de 48"     = "bandejas",
        "Preformado Fibra 48"     = "vkom")
@

\subsection{Extracción}

<<>>=
materiales_raw <- tbl(con, in_schema("md", "descarga_vista")) |> 
  select(fecha    = fecha_uso, 
         codigo   = codigo_ebs, 
         cantidad,
         tipo     = tipo_ticket,
         estado   = estado_descarga_item, 
         ticketid = ticket,
         material = nombre_informal) |> 
  filter(codigo %in% materiales_criticos) |> 
  collect()
@

<<>>=
materiales_raw |> slice_sample(n = 5) |> select(-codigo) |> tabla("Detalle de Materiales")
@


<<include=FALSE>>=
dbDisconnect(con)
@

\subsection{Preparación}

Trabajaremos los datos en formato \emph{tidy}, por lo que es necesario preparar esto y
guardarlo en un objeto por separado.

<<>>=
materiales_long <- materiales_raw |> 
  mutate(
    across(material, recode, !!!mk), 
    mtto = case_when(
      str_detect(tipo, "correctivo") ~ "correctivo",
      TRUE ~ "preventivo"),
    across(fecha, as.Date)) |> 
  select(fecha, ticketid, codigo, material, estado, mtto, cantidad) |> 
  filter(estado != "rechazado")
@

<<>>=
materiales_long |> slice_sample(n = 5) |> tabla("Materiales Tidy")
@

Vemos en la tabla que ahora los materiales están en un formato largo, pero aun están con
intervalos irregulares. Lo siguiente es agrupar y sumarizar los datos por mes para poder
regularizar la serie a la vez que convertimos este tibble en un \texttt{tsibble}.

<<>>=
por_mes <- materiales_long |>
 filter(estado == "aplicado") |> 
 group_by(date = floor_date(fecha, unit = "month"), material) |> 
 summarise(cantidad = sum(cantidad), .groups = "drop") |> 
 drop_na() |> 
 mutate(fecha = yearmonth(date), .before = 1) |> 
 as_tsibble(key = material, index = fecha) |> 
 filter_index("2017 Jan" ~ "2021 Dec")
@

<<>>=
por_mes |> as_tibble() |> select(-date) |> slice_sample(n = 5) |> tabla("Agrupado por Mes")
@

\subsection{Gráfica}

\begin{figure}[H]
<<>>=
por_mes |> graficar(cantidad, .brk = material) |> agregar_info()
@
\caption{Interpretación de resultados}
   \label{fig:serie}
\end{figure}

\begin{shaded}
En el gráfico \ref{fig:serie} podemos ver una serie consistente de 260 semanas de datos
históricos en la que se observa una tendencia a la alza a partir de julio de 2018. Al
observar una tendencia creciente decimos que esta serie es \textbf{no estacionaria en la
media.} En el caso de las mufas, adicional a la tendencia, vemos que la variabilidad se
modifica con el tiempo, por lo que esta serie es \textbf{no estacionaria en la varianza.}
Los picos y valles no se repiten a lo largo de los años de forma constante, así que
deberemos evaluar la estacionalidad de manera más formal o con técnicas de descomposición.
\end{shaded}

\begin{shaded}
Parece haber una correlación entre el consumo de fibra y de mufas. Esto sucede
debido a que cada porción de fibra que se utiliza para reparaciones requiere por lo general
MUFAS para realizar los empalmes. También es probable que exista una estacionalidad para
todos los años en los meses de marzo y septiembre, con la excepción del 2017 y 2018 en marzo.
\end{shaded}


\subsection{Autocorrelación}

Aquí comprobamos la nueva forma de hacerlo con los paquetes de $\left \{fpp3 \right \}$ en
lugar de las funciones base.

La prueba de Ljung-Box lo que prueba es la aleatoriedad general en función de una serie de
retrasos.

\textbf{Hipótesis nula:} las autocorrelaciones, hasta un retardo o lag determinado, son
iguales a cero.

<<>>=
Box.test(diff(fpp2::goog200), lag = 10, type = "Ljung-Box")
@

<<>>=
fpp2::goog200 |>
 as_tsibble() |> 
 mutate(diferencia = difference(value)) |> 
 features(diferencia, ljung_box, lag = 10) |> 
 tabla("Ljung-Box para datos de prueba")
@

Si el p-valor es mayor al nivel de significancia decimos que la serie es estacionaria, como
lo es en este caso.

Ahora evaluemos nuestra serie

\begin{figure}[H]
<<>>=
por_mes |> group_by(material) |> ACF(cantidad) |> autoplot()
@
\caption{Interpretación de resultados}
   \label{fig:corre}
\end{figure}

Sabemos que para una serie estacionaria el correlograma caerá a cero relativamente rápido con
un decaimiento exponencial. Para una serie no estacionaria el ACF disminuye lentamente, un
decaimiento lento con una persistencia. Además, para datos no estacionarios, el valor de la
primera autocorrelación es a menudo grande.

\begin{shaded}
Hay más información en el gráfico ACF que en el diagrama de serie de tiempo simple de la
figura \ref{fig:serie}. Aquí vemos que, para el caso de la fibra48 el primero, tercero y
cuarto retardo superan claramente la línea azul, lo que sugiere que es posible alguna señal
en este componente de la serie de tiempo que se puede utilizar para crear un modelo.
\end{shaded}

Ahora realizamos la prueba de Ljung-Box para evaluar la "aleatoriedad general" en las
primeras 17 autocorrelaciones de retraso.

<<>>=
por_mes |> 
 group_by(material) |> 
 mutate(diferencia = difference(cantidad)) |> 
 features(diferencia, ljung_box, lag = 17) |> 
 tabla("Prueba de autocorrelación")
@

\begin{shaded}
Como ($p < .05$), rechazamos la hipótesis nula y por tanto existe correlación para algún
retardo menor que 17. Existe autocorrelación en la serie temporal, lo cual es consistente con
lo que vemos en el gráfico ACF de la figura \ref{fig:corre} anterior, la serie temporal
muestra un patrón de comportamiento particular que podemos utilizar para su modelado.
\end{shaded}

\subsection{Tranformación}

Para los datos mensuales de materiales vamos a tomar diferencias estacionales sobre la serie
en logaritmo. Los datos se transforman primero usando logaritmos. \textbf{El logaritmo
natural puede linearizar una tendencia de crecimiento rápido, una tendencia de aumento
exponencial.} La restricción es que todos los valores deben ser positivos.

Existen algunas diferencias entre la función \texttt{base::diff} y la función
\texttt{tsibble::difference}. Esta última deja valores NA en el tsibble, por lo que el
ggplot enviará un warning si no se elimnan.  Otro punto a considerar es que para las
diferencias estacionales el parámetro que hay que utilizar es \texttt{lag = 12}.

\subsubsection{Diferenciar}

Las transformaciones como los logaritmos pueden ayudar a estabilizar la varianza de una serie
temporal. La diferenciación puede ayudar a estabilizar la media de una serie temporal
eliminando los cambios en el nivel de una serie temporal y, por lo tanto, eliminando (o
reduciendo) la tendencia y la estacionalidad.

\im{Diferencia estacional}

Cuando se aplican tanto las diferencias estacionales como las diferencias regulares (o
diferencias primeras), no importa qué se haga primero: el resultado será el mismo. Sin
embargo, si los datos tienen un patrón estacional fuerte, \textbf{recomendamos que la
diferenciación estacional se haga primero}, porque la serie resultante a veces será
estacionaria y no habrá necesidad de una primera diferencia adicional. Si primero se hace la
diferenciación, todavía habrá presente estacionalidad.

Las primeras diferencias son el cambio entre una observación y la siguiente. Las diferencias
estacionales son el cambio de un año a otro. Es poco probable que otros retardos tengan mucho
sentido interpretable y deben evitarse.

<<>>=
fibra_estacionaria <- por_mes |> 
  filter(material == "fibra48") |> 
  mutate(
    log_cantidad          = log(cantidad), 
    diferencia_estacional = difference(log_cantidad, lag = 12), # desviaciones mensuales
    primera_diferencia    = difference(diferencia_estacional)) %>% 
  pivot_longer(cols       = where(is.numeric), 
               names_to   = "tipo",
               values_to  = "cantidad_d") |> 
  mutate(tipo = fct_inorder(tipo))
@


<<fig.asp=0.8>>=
fibra_estacionaria |> 
  graficar(vector = cantidad_d, .brk = tipo) 
@

Ahora sí la serie parece ser estacionaria, aunque siempre vemos al inicio un pico y un valle
bastante pronunciado.

\im{Prueba de Ljung-Box. Hipótesis nula H0: errores no correlacionados hasta el lag d}

Podemos

<<>>=
fibra_estacionaria |>
 features(cantidad_d, features = list(lj = ljung_box(lag = 10)))	
@

Ahora vemos un método un poco más automático para comprobar todas las transformaciones

<<>>=
fibra_estacionaria |> 
 as_tibble() |>
 select(tipo, cantidad_d) |> 
 group_nest(tipo) |>
 mutate(
 	lb_stat   = map(data, ~ ljung_box(.x, lag = 10)[[1]]),
 	lb_pvalue = map(data, ~ ljung_box(.x, lag = 10)[[2]]), 
 	.keep = "unused") |> 
 unnest(cols = lb_stat:lb_pvalue)
@

Como p<0.05, rechazamos la hipótesis nula y por tanto existe correlación para algún retar
o menor que 10. Existe autocorrelación en la serie temporal, información que puede ser
interesante capturar en un modelo


\ro{Pendiente ver todas las pruebas que trae el paquete feast}

Rosana indica que la mejor prueba es la KSS

<<>>=
# fibra_estacionaria |>
#  filter(tipo == "cantidad") |> 
#  features(cantidad_d, feature_set(pkgs = "feast"))	
@

\im{Prueba ADF: Hipótesis nula H0: serie no estacionaria}

\section{Autocorrelación parcial}































