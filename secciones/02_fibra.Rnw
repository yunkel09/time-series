\chapter{Caso de uso - Fibra óptica}

Para poder ver como los conceptos se van aplicando, consideremos un caso de uso en el que
analizaremos las series de tiempo de dos materiales que se utilizan con frecuencia en PLEX.
El objetivo final es probar varios modelos y realizar un pronóstico de consumo para un
horizonte adecuado. Las preguntas de investigación estarán relacionados a la presencia de
valores atípicos y la cantidad de datos necesaria para poder realizar un buen pronóstico. 
También es importante destacar que el consumo de estos materiales se divide en dos grandes
rubros, los cuales son el mantenimiento preventivo y el correctivo.  Una interrogante será
si las series deben pronosticarse por separado en vista de que es posible de que los procesos
implícitos que generan cada serie son diferentes.

El primer paso es conectarnos a nuestra base de datos para extraer la tabla donde se
almacenan los datos históricos de consumo.

<<>>=
con <- conectar_msql()
@

Debido a que hay muchos códigos que se utilizan para identificar un mismo tipo de material,
será necesario realizar una preparación.  Comencemos definiendo algunos parámetros para
poder descargar solo el material necesario, delegando de esta forma al servidor la tarea de
realizar la consulta y entregarnos lo que necesitamos.

<<>>=
materiales_criticos <- c("OSP0001440",  # MUFA PARA FIBRA 48 COLOR AZUL
                         "OSP0000111",  # FIBER OPTIC CABLE ADSS FOR 150 METER
                         "OSP0001313",  # FIBER OPTIC CABLE ADSS FOR 150 METER GAPS 48 HILOS
                         "OSP0001142",
                         "OSP0000193",  # MUFA PARA FIBRA 48 HILOS VERTICAL     
                         "ACC005283")	  # MUFA ONE
@

Para cada tipo de material, hay dos tipos de consumo:

<<>>=
tipos_mantenimiento <- c(correctivo = "correctivo", preventivo = "preventivo")
@

Creemos una lista que nos permita acortar los nombres informales de los materiales:

<<>>=
mk <- c("Mufa 48 Hilos"           = "mufa48",
        "Fibra 48 Hilos vano 150" = "fibra48",
        "Bandejas Mufa de 48"     = "bandejas",
        "Preformado Fibra 48"     = "vkom")
@

\subsection{Extracción}

<<>>=
materiales_raw <- tbl(con, in_schema("md", "descarga_vista")) |> 
  select(fecha    = fecha_uso, 
         codigo   = codigo_ebs, 
         cantidad,
         tipo     = tipo_ticket,
         estado   = estado_descarga_item, 
         ticketid = ticket,
         material = nombre_informal) |> 
  filter(codigo %in% materiales_criticos) |> 
  collect()
@

<<>>=
materiales_raw |> slice_sample(n = 5) |> select(-codigo) |> tabla("Detalle de Materiales")
@


<<include=FALSE>>=
dbDisconnect(con)
@

\subsection{Preparación}

Trabajaremos los datos en formato \emph{tidy}, por lo que es necesario preparar esto y
guardarlo en un objeto por separado.

<<>>=
materiales_long <- materiales_raw |> 
  mutate(
    across(material, recode, !!!mk), 
    mtto = case_when(
      str_detect(tipo, "correctivo") ~ "correctivo",
      TRUE ~ "preventivo"),
    across(fecha, as.Date)) |> 
  select(fecha, ticketid, codigo, material, estado, mtto, cantidad) |> 
  filter(estado != "rechazado")
@

<<>>=
materiales_long |> slice_sample(n = 5) |> tabla("Materiales Tidy")
@

Vemos en la tabla que ahora los materiales están en un formato largo, pero aun están con
intervalos irregulares. Lo siguiente es agrupar y sumarizar los datos por mes para poder
regularizar la serie a la vez que convertimos este tibble en un \texttt{tsibble}.

<<>>=
por_mes <- materiales_long |>
 filter(estado == "aplicado") |> 
 group_by(date = floor_date(fecha, unit = "month"), material) |> 
 summarise(cantidad = sum(cantidad), .groups = "drop") |> 
 drop_na() |> 
 mutate(fecha = yearmonth(date), .before = 1) |> 
 as_tsibble(key = material, index = fecha) |> 
 filter_index("2017 Jan" ~ "2021 Dec")
@

<<>>=
por_mes |> as_tibble() |> select(-date) |> slice_sample(n = 5) |> tabla("Agrupado por Mes")
@

<<>>=
vk <- por_mes |> filter(material == "vkom")
brk <- hist(vk$cantidad, plot = F)$breaks
vk |> 
 ggplot(aes(x = cantidad, y = ..density..)) +
 geom_histogram(fill = "#56B4E9", size = .2, breaks = brk, color = "white") +
 geom_density(size = 1) +
 # geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
 # geom_vline(xintercept = res[["media"]], color = "black", linetype = "dashed") +
 scale_x_continuous(name = "Cantidad de preformados") +
                    # labels = dollar, expand = c(0, 0),
                    # limits = c(-2.2, 1.5),
                    # breaks = seq(-2.2, 1.2, 0.4))  +
 labs(title = "Distribución de unidades") + furia
@



\subsection{Gráfica}

\begin{figure}[H]
<<>>=
por_mes |> graficar(cantidad, .brk = material) |> agregar_info()
@
\caption{Interpretación de resultados}
   \label{fig:serie}
\end{figure}

\begin{shaded}
En el gráfico \ref{fig:serie} podemos ver una serie consistente de 260 semanas de datos
históricos en la que se observa una tendencia a la alza a partir de julio de 2018. Al
observar una tendencia creciente decimos que esta serie es \textbf{no estacionaria en la
media.} En el caso de las mufas, adicional a la tendencia, vemos que la variabilidad se
modifica con el tiempo, por lo que esta serie es \textbf{no estacionaria en la varianza.}
Los picos y valles no se repiten a lo largo de los años de forma constante, así que
deberemos evaluar la estacionalidad de manera más formal o con técnicas de descomposición.
\end{shaded}

\begin{shaded}
Parece haber una correlación entre el consumo de fibra y de mufas. Esto sucede
debido a que cada porción de fibra que se utiliza para reparaciones requiere por lo general
MUFAS para realizar los empalmes. También es probable que exista una estacionalidad para
todos los años en los meses de marzo y septiembre, con la excepción del 2017 y 2018 en marzo.
\end{shaded}


\subsection{Autocorrelación}

Aquí comprobamos la nueva forma de hacerlo con los paquetes de $\left \{fpp3 \right \}$ en
lugar de las funciones base.

La prueba de Ljung-Box lo que prueba es la aleatoriedad general en función de una serie de
retrasos.

\textbf{Hipótesis nula:} las autocorrelaciones, hasta un retardo o lag determinado, son
iguales a cero.

<<>>=
Box.test(diff(fpp2::goog200), lag = 10, type = "Ljung-Box")
@

<<>>=
fpp2::goog200 |>
 as_tsibble() |> 
 mutate(diferencia = difference(value)) |> 
 features(diferencia, ljung_box, lag = 10) |> 
 tabla("Ljung-Box para datos de prueba")
@

Si el p-valor es mayor al nivel de significancia decimos que la serie es estacionaria, como
lo es en este caso.

Ahora evaluemos nuestra serie

\begin{figure}[H]
<<>>=
por_mes |> group_by(material) |> ACF(cantidad) |> autoplot()
@
\caption{Interpretación de resultados}
   \label{fig:corre}
\end{figure}

Sabemos que para una serie estacionaria el correlograma caerá a cero relativamente rápido con
un decaimiento exponencial. Para una serie no estacionaria el ACF disminuye lentamente, un
decaimiento lento con una persistencia. Además, para datos no estacionarios, el valor de la
primera autocorrelación es a menudo grande.

\begin{shaded}
Hay más información en el gráfico ACF que en el diagrama de serie de tiempo simple de la
figura \ref{fig:serie}. Aquí vemos que, para el caso de la fibra48 el primero, tercero y
cuarto retardo superan claramente la línea azul, lo que sugiere que es posible alguna señal
en este componente de la serie de tiempo que se puede utilizar para crear un modelo.
\end{shaded}

Ahora realizamos la prueba de Ljung-Box para evaluar la "aleatoriedad general" en las
primeras 17 autocorrelaciones de retraso.

<<>>=
por_mes |> 
 group_by(material) |> 
 mutate(diferencia = difference(cantidad)) |> 
 features(diferencia, ljung_box, lag = 17) |> 
 tabla("Prueba de autocorrelación")
@

\begin{shaded}
Como ($p < .05$), rechazamos la hipótesis nula y por tanto existe correlación para algún
retardo menor que 17. Existe autocorrelación en la serie temporal, lo cual es consistente con
lo que vemos en el gráfico ACF de la figura \ref{fig:corre} anterior, la serie temporal
muestra un patrón de comportamiento particular que podemos utilizar para su modelado.
\end{shaded}

\subsection{Tranformación}

Para los datos mensuales de materiales vamos a tomar diferencias estacionales sobre la serie
en logaritmo. Los datos se transforman primero usando logaritmos. \textbf{El logaritmo
natural puede linearizar una tendencia de crecimiento rápido, una tendencia de aumento
exponencial.} La restricción es que todos los valores deben ser positivos.

Existen algunas diferencias entre la función \texttt{base::diff} y la función
\texttt{tsibble::difference}. Esta última deja valores NA en el tsibble, por lo que el
ggplot enviará un warning si no se elimnan.  Otro punto a considerar es que para las
diferencias estacionales el parámetro que hay que utilizar es \texttt{lag = 12}.

\subsubsection{Diferenciar}

Las transformaciones como los logaritmos pueden ayudar a estabilizar la varianza de una serie
temporal. La diferenciación puede ayudar a estabilizar la media de una serie temporal
eliminando los cambios en el nivel de una serie temporal y, por lo tanto, eliminando (o
reduciendo) la tendencia y la estacionalidad.

\im{Diferencia estacional}

Cuando se aplican tanto las diferencias estacionales como las diferencias regulares (o
diferencias primeras), no importa qué se haga primero: el resultado será el mismo. Sin
embargo, si los datos tienen un patrón estacional fuerte, \textbf{recomendamos que la
diferenciación estacional se haga primero}, porque la serie resultante a veces será
estacionaria y no habrá necesidad de una primera diferencia adicional. Si primero se hace la
diferenciación, todavía habrá presente estacionalidad.

Las primeras diferencias son el cambio entre una observación y la siguiente. Las diferencias
estacionales son el cambio de un año a otro. Es poco probable que otros retardos tengan mucho
sentido interpretable y deben evitarse.

<<>>=
fibra_estacionaria <- por_mes |> 
  filter(material == "fibra48") |> 
  mutate(
    log_cantidad          = log(cantidad), 
    diferencia_estacional = difference(log_cantidad, lag = 12), # desviaciones mensuales
    primera_diferencia    = difference(diferencia_estacional)) %>% 
  pivot_longer(cols       = where(is.numeric), 
               names_to   = "tipo",
               values_to  = "cantidad_d") |> 
  mutate(tipo = fct_inorder(tipo))
@


<<fig.asp=0.8>>=
fibra_estacionaria |> 
  graficar(vector = cantidad_d, .brk = tipo) 
@

Ahora sí la serie parece ser estacionaria, aunque siempre vemos al inicio un pico y un valle
bastante pronunciado.

\im{Prueba de Ljung-Box. Hipótesis nula H0: errores no correlacionados hasta el lag d}

Podemos

<<>>=
fibra_estacionaria |>
 features(cantidad_d, ljung_box, lag = 10)	
@

Ahora vemos un método un poco más automático para comprobar todas las transformaciones

<<>>=
fibra_estacionaria |> 
 as_tibble() |>
 select(tipo, cantidad_d) |> 
 group_nest(tipo) |>
 mutate(
 	lb_stat   = map(data, ~ ljung_box(.x, lag = 10)[[1]]),
 	lb_pvalue = map(data, ~ ljung_box(.x, lag = 10)[[2]]), 
 	.keep = "unused") |> 
 unnest(cols = lb_stat:lb_pvalue)
@

Como p<0.05, rechazamos la hipótesis nula y por tanto existe correlación para algún retar
o menor que 10. Existe autocorrelación en la serie temporal, información que puede ser
interesante capturar en un modelo


\ro{Pendiente ver todas las pruebas que trae el paquete feast}

Rosana indica que la mejor prueba es la KSS

<<>>=
# fibra_estacionaria |>
#  filter(tipo == "cantidad") |> 
#  features(cantidad_d, feature_set(pkgs = "feast"))	
@

\im{Prueba ADF: Hipótesis nula H0: serie no estacionaria}

\section{Autocorrelación parcial}




















