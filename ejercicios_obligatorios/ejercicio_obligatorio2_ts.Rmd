---
title: Time Series
subtitle: Ejercicio Obligatorio II
author:
- name: William Chavarría
  affiliation: Máxima Formación
  email: wchavarria@tigo.com.gt
date: '`r format(Sys.Date())`'
output: 
  bookdown::html_document2:
    toc: true
    toc_float: true
    highlight: pygments
    theme: spacelab
    css: custom.css
    fig_caption: true
    df_print: paged
    # includes: header.html
bibliography: [paquetes.bib, ts.bib]
biblio-style: "apalike"
link-citations: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo        = TRUE, 
                      include     = TRUE,
                      cache       = FALSE,
                      fig.align   = 'center',
                      message     = FALSE,
                      warning     = FALSE, 
                      comment     = NA, 
                      highlight   = TRUE,
                      strip.white = TRUE,
                      dev         = "svglite",
                      fig.width   = 11,
                      fig.asp     = 0.5,
                      fig.show    = "hold",
                      fig.align   = "center")
```

# Índice de comercio {.tabset .tabset-fade .tabset-pills}

## Descripción

Analiza los datos trimestrales del comercio minorista europeo de 1996 a 2011. El objeto con
los datos se llama euretail y se encuentra disponible en el paquete fpp2.

1. Importa/activa y grafica la serie;
2. Si es necesario, busca una transformación log(), diff() o Box-Cox adecuada para los datos; 
3. Analiza los correlograma y discute los modelos candidatos.
4. Estima un modelo ARIMA utilizando la función automática auto.arima(); ¿coincide con tus modelos candidatos?
5. De ser necesario, ajusta un modelo alternativo con la función Arima().
6. ¿Qué tipo de modelo has obtenido? interpreta los resultados.
7. Comprueba la validez del modelo realizando un diagnóstico de los residuos;
8. Realiza predicciones con el modelo ajustado. ¿Las previsiones parecen razonables?

## Paquetes

```{r}
options(warn = -1,
		  scipen = 1,
		  dplyr.summarise.inform = FALSE,
		  tibble.print_min = 5,
		  pillar.sigfig = 4,
		  readr.show_col_types = FALSE)
```


```{r}
import::from(magrittr, "%<>%", "%$%", .into = "operadores")
import::from(zeallot, `%<-%`)
import::from(kableExtra, .except = "group_rows")
import::from(conectigo, cargar_fuentes)
import::from(janitor, clean_names)
import::from(tseries, adf.test)
import::from(forecast, .except = c("accuracy", "forecast"))
import::from(cowplot, .except = "stamp")
import::from(glue, glue)
import::from(statistigo, coloring_font)
import::from(colorblindr, scale_color_OkabeIto)
import::from(tsutils, coxstuart)
import::from(ggpmisc, stat_peaks, stat_valleys, stat_correlation)
pacman::p_load(tictoc, scales, pins, tsbox, latex2exp, fpp3, tidyverse)
```

## Funciones

```{r}
# calcular retardos significativos
retardos <- function(df, fun, columna) {
 ul <- 1.96 / sqrt(nrow(df) - 1)
 no <- tolower(deparse(substitute(fun)))
 df |> fun({{ columna }}) |> 
  filter(!between(x = .data[[no]], left = (ul * -1), right = ul)) |> 
  mutate(across(where(is.numeric), round, 3))
}
```


```{r}
agregar_info <- function(gg_object, spa = 7) {
 gg_object +
  stat_peaks(geom = "point", span = spa, color = "red", size = 1) +
  stat_valleys(geom = "point", span = spa, color = "blue", size = 1) +
  stat_peaks(geom = "text",
             span = spa,
             color = "red",
             vjust = 0,
             hjust = -0.2,
             x.label.fmt = "%b-%Y",
             size = 3) +
  stat_valleys(geom = "text",
               span = spa,
               color = "blue",
               vjust = 0,
               hjust = -0.3,
               x.label.fmt = "%b-%Y",
               size = 3)
}

```



```{r}
# pruebas formales de estacionariedad
est <- list(
  ljung = ~ ljung_box(diff(.x)),
  kpss  = ~ unitroot_kpss(.x), 
  # pp    = ~ unitroot_pp(.x),
  adf   = ~ adf.test(.x, alternative = "stationary") |>
                     tidy() |>
                     select(statistic, p.value) |>
                     as.numeric()
)
```


```{r}
tabla <- function(df, cap = "prueba") {
  df %>% 
   kbl(booktabs = TRUE, linesep = "", caption = cap, escape = F) %>% 
   kable_paper(lightable_options = "hover", full_width = F)}
```

```{r}
resaltar <- function(texto) {
 glue::glue("<span style='background-color: #FFFF00'>**{texto}**</span>")
}
```

```{r}
rlt <- function(texto, color) {
 a <- "<span style='background-color: "
 b <- "'>"
 c <- "</span>"
 t <- str_c("**", texto, "**")
 f <- str_c(a, color, b)
 glue::glue(f, t, c) 
}
```

```{r}
colort <- function(vec, colorv, paleta, usarv = T) {
	
	# show_col(viridis_pal(option = "turbo")(30))
	# paleta solo pueden ser A (magma), B (inferno), C (plasma),
	# D (viridis) y E(cividis)
	# rojo:     #F4354D
	# amarillo: #FCA108
	# verde:    #00AB40
	if (usarv == T) {
		
		cell_spec(vec,
				 color = "white",
				 bold = TRUE,
				 background = spec_color(x = colorv, 
				 								option = paleta, 
				 								direction = 1))
	} else {
		
		cell_spec(vec,
				 color = "white",
				 bold = TRUE,
				 background = colorv)
	}
	
	
}
```


```{r}
# es mejor usar notación científica para los p-valores
cient <- label_scientific()

# resultados del modelo con ARIMA
fun_list <- list(
 coeficientes  = function(df) df |> 
  tidy() |> 
	mutate(
		across(estimate:statistic, round, 4),
		across(p.value, cient)),
 bondad = function(df) df |> 
  glance() |>
 	arrange(AIC) |> # el menor AIC es el más parsimonioso
 	select(.model:BIC)
)

# extraer la información de los modelos para comparar
ajustar_modelos <- function(mdl, fun_list = fun_list) {
 fun_list |> 
  map(exec, df = mdl)
}
```



## Opciones

```{r}
colorx <- c(rojo = "#F4354D", amarillo = "#FCA108", verde = "#00AB40")
```

```{r}
cargar_fuentes()
```

```{r}
yunkel <- theme_cowplot(font_family = "yano") +
	       theme(plot.margin = unit(c(3, 1, 1, 1), "mm"), 
	             axis.title = element_text(size = 12))
```

```{r}
# tema con grid horizontal y vertical
drako <- theme_bw(base_family = "yano", base_size = 14) +
	      theme(plot.margin = unit(c(6, 1, 1, 1), "mm"),
	            axis.title = element_text(size = 12),
	            plot.subtitle = element_text(size = 8,
                                            family = "sans"))
```

```{r}
theme_set(drako)
```

# Load

```{r}
euro_raw <- fpp2::euretail
euro <- euro_raw |> as_tsibble() |> rename(fecha = index)
```

```{r, paged.print = FALSE}
head(euro) |> tabla(cap = "Índice Comercial")
```

# EDA

(ref:gr-01) Gráfica de la serie

```{r, gr-01, fig.cap='(ref:gr-01)'}
(euro |> ggplot(aes(x = fecha, y = value)) +
 geom_line()) |> 
 agregar_info() +
 labs(title = "Índice trimestral de comercio al por menor en la zona del euro (17 países), 1996-2011",
 	   subtitle = "Cubre el comercio al por mayor y al por menor, y la reparación de vehículos de motor y motocicletas")
```

El gráfico de tiempo revela inmediatamente algunas características interesantes.

- Hubieron dos puntos de inflexión importantes. El primero, una caída del índice de Octubre
de 1996 a enero de 1997 cuando empezó a recuperarse.  La segunda y más notable, se dió a
partir de Octubre del 2000, finalizando en Enero de 2001.  

- La serie evoluciona con una tendencia fuerte hasta llegar aun *punto de cambio* en octubre
de 2007 cuando cae de forma sostenida hasta que se estabiliza en aproximadamente 97 puntos
en octubre de 2010, pero nunca regresa a sus niveles anteriores.

- La muestra una fuerte tendencia a la alza. La serie no es estacionaria en la **media**.

- A simple vista no se aprecia estacionalidad.

## Componentes

```{r}
euro |> model(stl = STL(value)) |> components() |> autoplot()
```

</br>

Las barras grises a la izquierda de cada panel muestran las escalas relativas de los
componentes. Cada barra gris representa la misma longitud pero debido a que las gráficas
están en diferentes escalas, las barras varían en tamaño. La barra gris grande en el panel
del medio muestra que la variación en el componente restante es menor en comparación con la
variación en los datos.

<p class="comment">
La descomposición detectó un componente de tendencia muy fuerte, así como estacionalidad.
</p>

## Tendencia

Veamos si la tendencia observada es significativa

```{r}
euro %$%
 coxstuart(value) |> 
 bind_rows() |>
 clean_names() |> 
 tabla(cap = "Prueba de tendencia")
```

</br>

<p class="comment">
Obtenemos que la tendencia es significativa
</p>

## Estacionalidad

(ref:gr-02) Resumen gráfico

```{r, gr-02, fig.cap='(ref:gr-02)'}
euro |> 
 gg_season(value, labels = "both") +
 labs(y = "Indice Comercial", 
 	  title = "Gráfico estacional: Índice comercial en la zona del Euro")
```

<br/>

<p class="comment">
En el gráfico \@ref(fig:gr-02) se observa que los años anteriores al 2008, vemos un patrón
de salto en el crecimiento entre el Q1 y el Q2, al igual que del Q2 al Q3.  Entre el Q3 y
Q4 el índice es estable con la excepción de los años de 1996 a 1999, donde si se aprecia
un incremento.
</p>

(ref:gr-03) Resumen gráfico

```{r, gr-03, fig.cap='(ref:gr-03)'}
euro |> 
 gg_subseries(value) +
 labs(y = "Indice Comercial", 
 	   title = "Gráfico estacional: Índice comercial en la zona del Euro")
```

<br/>

<p class="comment">
En el gráfico \@ref(fig:gr-03) se observa que lo que indicábamos en el gráfico
\@ref(fig:gr-02) de que, en términos generales, para la mayoría de años, se ve un crecimiento
del índice en el Q4.
</p>



## Estacionariedad

Veamos los retardos significativos en un correlograma. Para esto, utilizaremos la función
`retardos()`, la cual devuelve los valores de lag al igual que la función
`ggAcf(euro_raw, plot = F)` con la diferencia de que solo devuelve los lags que son
significativos. 

### Prueba informal

Grafiquemos el correlograma de la serie **sin transformar** solo para efectos de poder
evaluar si la serie es estacionaria.

(ref:gr-04) ACF Volcan sin transformar

```{r, gr-04, fig.cap='(ref:gr-04)'}
euro |> gg_tsdisplay(value, plot_type = "partial")
```

<br/>

```{r, retar}
retardos(euro, ACF, columna = value) |> 
 left_join(retardos(euro, PACF, value), by = "lag") |> 
 tabla(cap = "Retardos significativos en ACF y PACF")
```

<br/>

<p class="comment">
Tanto en el gráfico \@ref(fig:gr-02) como en la tabla \@ref(tab:retar) se observa que las
autocorrelaciones para los retardos que van del 1 al 13 en el ACF exceden los límites de
significancia, y que las autocorrelaciones descienden a cero después del retardo 13. Las
autocorrelaciones para los retardos del 1 al 13 son positivas y disminuyen en magnitud al
aumentar retardo.
</p>

<p class="comment">
En el autocorrelograma parcial, vemos que la autocorrelación parcial en el retardo 1 es
positiva y excede los límites de significancia (0.956), mientras que la autocorrelación
parcial en el retardo 5 es negativa y también excede los límites de significancia (-0.26).
</p>

Cuando los datos tienen una tendencia, las autocorrelaciones para pequeños retrasos tienden a
ser grandes y positivas porque las observaciones cercanas en el tiempo también tienen un
valor cercano. Entonces, el ACF de una serie de tiempo con tendencia tiende a tener valores
positivos que disminuyen lentamente a medida que aumentan los retrasos.

`r resaltar("El decrecimiento lento (persistencia) en el ACF indica que la serie no
es estacionaria.")`

### Pruebas formales

```{r}
euro_test <- euro |> 
 as_tibble() |> 
 summarise(across(value, est)) |> 
 slice(2) |> 
 rename_with(~ str_remove_all(.x, "value_")) |> 
 pivot_longer(cols = everything(), 
              names_to = "test",
              values_to = "p_valor") |> 
 mutate(null_hypothesis = c("stationarity", "stationarity", "non-stationarity"))
```


```{r, formal-test}
euro_test |> 
 mutate(resultado = c("no-estacionaria", 
                      "no-estacionaria",
                      "no-estacionaria")) |> 
 tabla(cap = "Pruebas formales de estacionariedad")
```

Los resultados de los test de estacionaridad son consistentes

</br>

# Transformación

Las transformaciones como los logaritmos pueden ayudar a estabilizar la varianza de una serie
temporal. La diferenciación puede ayudar a estabilizar la media de una serie temporal
eliminando los cambios en el nivel de una serie temporal y, por lo tanto, eliminando (o
reduciendo) la tendencia y la estacionalidad.

## Diferencias


```{r, nd}
euro |> 
 features(log(value), features = list(unitroot_ndiffs,
                                      unitroot_nsdiffs)) |> 
 tabla("Diferencias")
```

<p class="comment">
Vemos en la tabla \@ref(tab:nd) que se requieren 2 diferencias para que los datos de comercio
sean estacionarios.  Una diferencia estacional yuna primera diferencia. También vemos que se
requiere al menos una diferencia estacional.  Auque se sugiere que cuando $F_{s} \leq 64$ no
es necesario aplicar una diferencia estacional.
</p>

(ref:gr-05) Resumen gráfico

```{r, gr-05, fig.cap='(ref:gr-05)'}
euro |> 
 mutate(log_value = log(value)) |> 
 pivot_longer(value:log_value, "variable", "valor") |> 
 ggplot(aes(x = fecha, y = value)) +
 geom_line(aes(color = variable), size = 1) +
 scale_color_OkabeIto() +
 facet_grid(rows = vars(variable), scales = "free_y")
```

<br/>

En el gráfico \@ref(fig:gr-05) se observa como se ve la gráfica aplicando el logaritmo.
No hay evidencia de cambio de varianza, por lo que no haremos una transformación de Box-Cox.

```{r}
euro_diff <- euro |> 
 mutate(diff_estacional = difference(value, lag = 4), # son datos trimestrales
        primera_diff = difference(diff_estacional, lag = 1))
```

```{r, pdf}
euro_diff |> slice(1:20) |> tabla("Diferencia estacional y primera diferencia")
```

</br>
<p class="comment">
En la tabla \@ref(tab:pdf) vemos los resultados de la diferencia estacional aplicada al
logaritmo de los valores y luego vemos una primera diferencia aplicada a la diferencia
estacional.  Este procedimiento es lo mismo que si hubiéramos aplicado el método:
</p>


</br>

<div align="center">
`r coloring_font("**<tt>diff(diff(log(euro), lag = 12), lag = 1)</tt>**", color = "blue")`
</div>

Veamos si con esta primer diferencia, posterior a la diferenciación estacional es suficiente:


```{r}
euro_diff |> 
	features_at(.vars = vars(diff_estacional, primera_diff), 
					features = list(unitroot_ndiffs,
                               unitroot_nsdiffs)) |> 
	pivot_longer(everything(), 
					 names_to = c("var","stat"),
					 names_pattern = "(.*)_(.*)",
					 values_to = "valores") |> 
	pivot_wider(names_from = stat, values_from = valores) |> 
	tabla("La serie ya es estacionaria")
```

<p class="comment">
Vemos que la serie es estacionaria hasta después de aplicar la diferencia estaciona y la
primera diferencia, es decir, no se vuelve completamente estacional hasta que se haya
realizado una primera diferencia.
</p>

(ref:gr-06) Resumen gráfico

```{r, gr-06, fig.cap='(ref:gr-06)'}
euro_diff |> 
 pivot_longer(cols = value:primera_diff, names_to = "diferencias", values_to = "valor") |> 
 mutate(diferencias = factor(diferencias, levels = c("value",
 																	  "diff_estacional",
 												                 "primera_diff"))) |> 
 ggplot(aes(x = fecha, y = valor)) +
 geom_line() +
 facet_grid(rows = vars(diferencias), scales = "free_y") +
 labs(title = "Estacionarizar la serie")
```

<br/>

En el gráfico \@ref(fig:gr-06) se observa la serie original, la serie con una diferencia
estacional y la serie con una primera diferencia.


# Modelado

```{r}
gg_tsdisplay(euro_diff, primera_diff, plot_type = "partial") +
	labs(title = "Doble diferenciación")
```
`


<p class="comment">
El pico significativo en el retardo 1 en el ACF sugiere un componente no-estacional MA(1).
El pico significativo en el retardo 4 en el ACF sugiere un componente estacional MA(1).
Comencemos con un modelo ARIMA(0, 1, 1)(0, 1, 1)[4] indicando una primera diferencia, una
diferencia estacional, y componentes MA(1) no-estacional y MA(1) estacional. Si hubiéramos
empezado con el PACF, podríamos haber seleccionado un modelo ARIMA(1, 1, 0)(0, 1, 1)[4],
utilizando el PACF para seleccionar la parte no-estacional del modelo y el ACF para
seleccionar la parte estacional.
</p>

## Auto ARIMA

> Debido a que cortar una serie temporal en entrenamiento y prueba significa trabajar con
datos de dos períodos distintos. Si existe algún cambio en los patrones principales en esos
períodos, no tendría sentido hacerlo. De echo una opción en estos casos es detectar puntos de
cambio en la serie temporal y, de ser posible por el tamaño, ajustar modelos distintos para
los períodos identificados. Por tanto, no hay un único procedimiento correcto, depende del
caso. 

Con base a lo anterior, vamos a utilizar **todo** el conjunto de datos para encontrar el
mejor modelo con `auto.arima()` y posteriormente realizaremos validación cruzada para
evaluar su capacidad predictiva.

Realizaremos el ajuste considerando los modelos observados AR(2) y MA(2) para luego dejar que
la función `auto.arima()` busque primeramente con valores por defectos y luego la haremos
buscar con los parámetros `stepwise = FALSE` y `greedy = FALSE` para que realice una búsqueda
profunda.

`r resaltar("Será necesario ajustar modelos alternativos:")`

```{r}
fit <- euro |> 
 model(arima011011 = ARIMA(value ~ pdq(0, 1, 1) + PDQ(0, 1, 1)),
       arima100011 = ARIMA(value ~ pdq(1, 1, 0) + PDQ(0, 1, 1)),
       auto  = ARIMA(value, stepwise = FALSE, approximation = FALSE, greedy = FALSE))
```


```{r, paged.print = FALSE}
fit |>
 pivot_longer(everything(),
 				  names_to  = "modelo",
 				  values_to = "orden")
```


```{r}
c(t1, t2) %<-% ajustar_modelos(fit, fun_list)
```


```{r, mejoraic}
t2 |> tabla("Bondad de ajuste")
```

<p class="comment">
En la tabla \@ref(tab:mejoraic) vemos que de los tres modelos ajustados, todos tienen un
AICc bastante similar, siendo el modelo elegido automáticamente un poco mejor que los que
intentamos determinar.
</p>


## Mejor AIC

```{r}
best_gof_model <- t2 |> 
 slice_min(order_by = AICc) |> 
 pull(.model)
```

```{r}
best_gof_model
```

# Interpretación

`r resaltar("¿coincide con tus modelos candidatos?")`

<p class="comment">
No, el mejor modelo no coincide con mis modelos candidatos. El modelo automático considera
tres retardos significativos en el ACF, sin embargo, solo se aprecian dos.  Incluso aunque
grafiquemos con un `lag_max = 50`. Aunque el retardo 2 está muy cerca del límite de confianza.
En la gráfica \@ref(fig:gr-07) vemos el ACF con más definición y los  patrones estacionales
son ligeramente más claros.
</p>


(ref:gr-07) Vista de ACF a mayores retardos

```{r, gr-07, fig.cap='(ref:gr-07)'}
ACF(euro_diff, primera_diff, lag_max = 50) |> 
	autoplot()
```

<br/>

`r resaltar("¿Qué tipo de modelo has obtenido?")`

<p class="comment">
El modelo obtenido es un ARIMA(0,1,3)(0,1,1)[4], lo que significa que se identificó una
componente no estacional MA(3) y un componente estacional MA(1)
</p>


# Diagnóstico

Realicemos un diagnóstico del mejor modelo obtenido con auto.arima para que después lo
podamos comparar con validación cruzada.

(ref:gr-08) Análisis de residuos

```{r, gr-08, fig.cap='(ref:gr-08)'}
fit |> 
 select(any_of(best_gof_model)) |> 
 gg_tsresiduals(lag = 36) +
 labs(title = "Análisis de residuos")
```

<br/>

<p class="comment">
En el gráfico \@ref(fig:gr-08) se observa que los residuos no muestran un patrón evidente. 
No hay picos significativos en 36 retardos visualizados. La distribución de los residuos se
ve algo sesgada.
</p>


```{r}
augment(fit) |> 
 filter(.model == best_gof_model) |> 
 features(.innov, ljung_box, lag = 24, dof = 4) |> 
 tabla(cap = "Los residuos son ruido blanco")
```

</br>

<p class="comment">
El p-valor grande confirma que los residuos son similares al ruido blanco.
</p>

# Predicciones

(ref:gr-09) Pronóstico del índice comercial  utilizando un modelo ARIMA(0, 1, 3)(0, 1, 1)[4]. Se muestran los intervalos del 80% y 95%.

```{r, gr-09, fig.cap='(ref:gr-09)'}
forecast(fit, h = 15) %>%
 filter(.model == best_gof_model) %>%
 autoplot(euro, show_gap = F) +
 labs(title = "Predicción a 5 años (60 meses - 15 cuartos)",
      y = "Índice comercial")
```

<br/>


TODO:
1. Debo aclarar bien como utilizar cross-validación en lugar de train-test
2. En la predicción que acabo de hacer no uso ni train ni test. Es decir, no estoy evaluando
RMSE, simplemente me fue con el modelo que lo hacía mejor en entrenamiento.
3. En el ejercicio 1 debo corregir, a menos que el mejor modelo puesto a competir con
cross-validación es el que verdaderamente lo hace bien.  Creo que esto es. Debo de 
ponerlos a competir.  Mandarle la consulta a Rosana.



























