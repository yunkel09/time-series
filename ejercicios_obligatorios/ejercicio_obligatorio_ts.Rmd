---
title: Time Series
subtitle: Ejercicio Obligatorio I
author:
- name: William Chavarría
  affiliation: Máxima Formación
  email: wchavarria@tigo.com.gt
date: '`r format(Sys.Date())`'
output: 
  bookdown::html_document2:
    toc: true
    toc_float: true
    highlight: pygments
    theme: spacelab
    css: custom.css
    fig_caption: true
    df_print: paged
    # includes: header.html
bibliography: [paquetes.bib, ts.bib]
biblio-style: "apalike"
link-citations: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo        = TRUE, 
                      include     = TRUE,
                      cache       = FALSE,
                      fig.align   = 'center',
                      message     = FALSE,
                      warning     = FALSE, 
                      comment     = NA, 
                      highlight   = TRUE,
                      strip.white = TRUE,
                      dev         = "svglite",
                      fig.width   = 11,
                      fig.asp     = 0.5,
                      fig.show    = "hold",
                      fig.align   = "center")
```

# Volcan {.tabset .tabset-fade .tabset-pills}

## Descripción

Analiza la serie temporal sobre el índice de velo de polvo volcánico en el hemisferio
norte, de 1500-1969 (datos originales de Hipel y Mcleod, 1994), una medida del impacto de la
liberación de polvo y aerosoles de las erupciones volcánicas en el medio ambiente. El
archivo se encuentra disponible en: http://robjhyndman.com/tsdldata/annual/dvi.dat.

1. Importa/activa y grafica la serie;
2. Si es necesario, busca una transformación log(), diff() o Box-Cox adecuada para los datos; 
3. Analiza los correlograma y discute los modelos candidatos.
4. Estima un modelo ARIMA utilizando la función automática auto.arima(); ¿coincide con tus modelos candidatos?
5. De ser necesario, ajusta un modelo alternativo con la función Arima().
6. ¿Qué tipo de modelo has obtenido? interpreta los resultados.
7. Comprueba la validez del modelo realizando un diagnóstico de los residuos;
8. Realiza predicciones con el modelo ajustado. ¿Las previsiones parecen razonables?

## Paquetes

```{r}
options(warn = -1,
		  scipen = 1,
		  dplyr.summarise.inform = FALSE,
		  tibble.print_min = 5,
		  pillar.sigfig = 4,
		  readr.show_col_types = FALSE)
```


```{r}
import::from(magrittr, "%<>%", "%$%", .into = "operadores")
import::from(zeallot, `%<-%`)
import::from(kableExtra, .except = "group_rows")
import::from(conectigo, cargar_fuentes)
import::from(janitor, clean_names)
import::from(tseries, adf.test)
import::from(forecast, .except = c("accuracy", "forecast"))
import::from(cowplot, .except = "stamp")
import::from(glue, glue)
import::from(colorblindr, scale_color_OkabeIto)
import::from(tsutils, coxstuart)
import::from(ggpmisc, stat_peaks, stat_valleys, stat_correlation)
pacman::p_load(tictoc, scales, pins, tsbox, latex2exp, fpp3, tidyverse)
```

## Funciones

```{r}
# calcular retardos significativos
retardos <- function(df, fun) {
 ul <- 1.96 / sqrt(nrow(df) - 1)
 no <- tolower(deparse(substitute(fun)))
 df |> fun(value) |> 
  filter(!between(x = .data[[no]], left = (ul * -1), right = ul)) |> 
  mutate(across(where(is.numeric), round, 3))
}
```

```{r}
# pruebas formales de estacionariedad
est <- list(
  ljung = ~ ljung_box(diff(.x)),
  kpss  = ~ unitroot_kpss(.x), 
  pp    = ~ unitroot_pp(.x),
  adf   = ~ adf.test(.x, alternative = "stationary") |>
                     tidy() |>
                     select(statistic, p.value) |>
                     as.numeric()
)
```


```{r}
tabla <- function(df, cap = "prueba") {
  df %>% 
   kbl(booktabs = TRUE, linesep = "", caption = cap, escape = F) %>% 
   kable_paper(lightable_options = "hover", full_width = F)}
```

```{r}
resaltar <- function(texto) {
 glue::glue("<span style='background-color: #FFFF00'>**{texto}**</span>")
}
```

```{r}
rlt <- function(texto, color) {
 a <- "<span style='background-color: "
 b <- "'>"
 c <- "</span>"
 t <- str_c("**", texto, "**")
 f <- str_c(a, color, b)
 glue::glue(f, t, c) 
}
```

```{r}
colort <- function(vec, colorv, paleta, usarv = T) {
	
	# show_col(viridis_pal(option = "turbo")(30))
	# paleta solo pueden ser A (magma), B (inferno), C (plasma),
	# D (viridis) y E(cividis)
	# rojo:     #F4354D
	# amarillo: #FCA108
	# verde:    #00AB40
	if (usarv == T) {
		
		cell_spec(vec,
				 color = "white",
				 bold = TRUE,
				 background = spec_color(x = colorv, 
				 								option = paleta, 
				 								direction = 1))
	} else {
		
		cell_spec(vec,
				 color = "white",
				 bold = TRUE,
				 background = colorv)
	}
	
	
}
```


```{r}
# es mejor usar notación científica para los p-valores
cient <- label_scientific()

# resultados del modelo con ARIMA
fun_list <- list(
 coeficientes  = function(df) df |> 
  tidy() |> 
	mutate(
		across(estimate:statistic, round, 4),
		across(p.value, cient)),
 bondad = function(df) df |> 
  glance() |>
 	arrange(AIC) |> # el menor AIC es el más parsimonioso
 	select(.model:BIC)
)

# extraer la información de los modelos para comparar
ajustar_modelos <- function(mdl, fun_list = fun_list) {
 fun_list |> 
  map(exec, df = mdl)
}
```



## Opciones

```{r}
colorx <- c(rojo = "#F4354D", amarillo = "#FCA108", verde = "#00AB40")
```

```{r}
cargar_fuentes()
```

```{r}
yunkel <- theme_cowplot(font_family = "yano") +
	       theme(plot.margin = unit(c(3, 1, 1, 1), "mm"), 
	             axis.title = element_text(size = 12))
```

```{r}
# tema con grid horizontal y vertical
drako <- theme_bw(base_family = "yano", base_size = 14) +
	      theme(plot.margin = unit(c(6, 1, 1, 1), "mm"),
	            axis.title = element_text(size = 12),
	            plot.subtitle = element_text(size = 8,
                                            family = "sans"))
```

```{r}
theme_set(drako)
```

# Load

```{r, cache=TRUE}
volcan_raw <- scan("http://robjhyndman.com/tsdldata/annual/dvi.dat", skip = 1)
```

```{r}
head(volcan_raw)
```

# Prep

```{r}
volcan <- ts(volcan_raw, start = c(1500)) |> 
 ts_c() |> 
 ts_tbl() |> 
 mutate(year = 1500:1969) |> 
 rename(fecha = time) |> 
 relocate(year, .before = 1) |> 
 as_tsibble(index = year)
```

```{r}
volcan |> slice_head(n = 5) |> tabla(cap = "Objeto tsibble")
```

# EDA

(ref:gr-01) Gráfica de la serie

```{r, gr-01, fig.cap='(ref:gr-01)'}
volcan |> 
 ggplot(aes(x = fecha, y = value)) +
 geom_line() +
 stat_peaks(geom = "point", span = 61, color = "red", size = 2) +
 stat_peaks(geom = "text",
            span  = 61,
            color = "red",
            vjust = 0,
            hjust = -0.2,
            x.label.fmt = "%Y",
            size = 4)
```

<br/>

<p class="comment">
En el gráfico \@ref(fig:gr-01) se observa que La variabilidad no es del todo constante, sin
embargo, no se observa un patrón claro de variación (aumenta o disminuye la varianza en el
tiempo, o hay períodos con gran varianza, etc.). Por eso se puede decir que es bastante
estacionaria. La serie de tiempo parece ser estacionaria en media y varianza, ya que su nivel
y varianza parecen ser aproximadamente constantes en el tiempo. Por lo tanto, no parece que
necesitemos diferenciar.
</p>

## Componentes

```{r}
volcan |> model(stl = STL(value)) |> components() |> autoplot()
```

Las barras grises a la izquierda de cada panel muestran las escalas relativas de los
componentes. Cada barra gris representa la misma longitud pero debido a que las gráficas
están en diferentes escalas, las barras varían en tamaño. La barra gris grande en el panel
del medio muestra que la variación en el componente restante es menor en comparación con la
variación en los datos.

<p class="comment">
La descomposición no detectó un componente estacional.
</p>

## Tendencia

Veamos si la tendencia observada es significativa

```{r}
volcan %$%
 coxstuart(value) |> 
 bind_rows() |>
 clean_names() |> 
 tabla(cap = "Prueba de tendencia")
```

</br>

<p class="comment">
Obtenemos que la tendencia es significativa
</p>

## Estacionariedad

Veamos los retardos significativos en un correlograma. Para esto, utilizaremos la función
`retardos()` definida en la sección de funciones para que nos ayude a visualizar esto de
mejor forma:

### Prueba informal

Grafiquemos el correlograma de la serie **sin transformar** solo para efectos de poder
evaluar si la serie es estacionaria.

(ref:gr-02) ACF Volcan sin transformar

```{r, gr-02, fig.cap='(ref:gr-02)'}
volcan |> gg_tsdisplay(value, plot_type = "partial")
```

<br/>

```{r, retar}
retardos(volcan, ACF) |> 
 left_join(retardos(volcan, PACF), by = "lag") |> 
 tabla(cap = "Retardos significativos en ACF y PACF")
```

<br/>

<p class="comment">
Tanto en el gráfico \@ref(fig:gr-02) como en la tabla \@ref(tab:retar) se observa que las
autocorrelaciones para los retardos 1, 2 y 3 en el ACF exceden los límites de significancia,
y que las autocorrelaciones descienden a cero después del retardo 3. Las autocorrelaciones
para los retardos 1, 2, 3 son positivas y disminuyen en magnitud al aumentar retardo (retardo
1: 0,666, retardo 2: 0,374, retardo 3: 0,162. La autocorrelación para los retardos 19 y 20
también excede los límites de significancia, pero es probable que esto se deba al azar
(esperaríamos que 1 de cada 20 retardos exceda los límites de significación del 95% solo
por azar), ya que las autocorrelaciones para los retardos 4-18 no exceden los límites.
</p>


<p class="comment">
En el autocorrelograma parcial, vemos que la autocorrelación parcial en el retardo 1 es
positiva y excede los límites de significancia (0.666), mientras que la autocorrelación
parcial en el retardo 2 es negativa y también excede los límites de significancia (-0.126).
 Las autocorrelaciones parciales se reducen a cero después del retardo 2
</p>

### Pruebas formales

```{r, formal-test}
volcan |> 
 as_tibble() |> 
 summarise(across(value, est)) |> 
 slice(2) |> 
 rename_with(~ str_remove_all(.x, "value_")) |> 
 pivot_longer(cols = everything(), 
              names_to = "test",
              values_to = "p_valor") |> 
 mutate(null_hypothesis = c("stationarity", "stationarity", "non-stationarity",
                            "non-stationarity"),
 		  resultado = case_when(
 		  	p_valor < 0.05 & null_hypothesis == "stationarity" ~ "no_estacionaria",
 		  	p_valor < 0.05 & null_hypothesis == "non-stationarity" ~ "estacionaria",
 		  	TRUE ~ "estacionaria"
 		  )) |> 
 tabla(cap = "Pruebas formales de estacionariedad")
 
```

</br>

# Transformación

Tanto en la gráfica \@ref(fig:gr-01) como en las pruebas formales de la tabla
\@ref(tab:formal-test) vemos que una transformación **no es necesaria**, sin embargo para efectos
didacticos, analicemos las posibles transformaciones.


## Logaritmo

<p class="comment">
Aplicar una transformación logarítmica no es posible debido a que hay ceros. 
</p>

## Diferenciar

```{r}
volcan |> 
 features(value, features = list(unitroot_ndiffs,
                                 unitroot_nsdiffs)) |> 
 tabla("¿Hay necesidad de diferenciar?")
```

<p class="comment">
Como vemos no hay necesidad de aplicar diferenciación debido a que la serie
**es estacionaria.**
</p>

```{r}
volcan |> 
 mutate(primera_diferencia = difference(value),
        segunda_diferencia = difference(primera_diferencia)) |> 
 pivot_longer(cols = ends_with("cia"), names_to = "diff", values_to = "valores") |> 
 ggplot(aes(x = fecha, y = valores)) +
 geom_line(aes(color = diff)) +
 scale_color_OkabeIto() +
 facet_grid(diff ~ .) +
 theme(legend.position = "bottom", legend.title = element_blank())
	
```

<p class="comment">
Vemos una ausencia de cualquier aumento o disminución sostenidos en el nivel de la serie
posterior a la diferenciación; ahora vemos que fluctúa alrededor de un nivel medio constante
Un nivel medio constante es una condición, pero no la única, para que una serie sea
estacionaria. [@mills_applied_2019 pag 4]
</p>

## Box-Cox

```{r}
lam <- volcan |> 
 features(value, features = guerrero)
```

```{r}
volcan %<>% mutate(velo = box_cox(value, lam))
```

```{r}
volcan |> 
autoplot(velo) +
 labs(y = "", title = TeX(paste0(
  "Transformación del índice de velo volcánico con   $\\lambda$ = ",
  round(lam, 2)))) +
 theme_bw()
```

<p class="comment">
La varianza se ve más estable, aunque con valores negativos.
</p>

# Modelado

## Selección manual


(ref:gr-03) Correlograma de la serie sin diferenciar

```{r, gr-03, fig.cap='(ref:gr-03)'}
gg_tsdisplay(volcan, value, plot_type = "partial")
```

<br/>

<p class="comment">
En el gráfico \@ref(fig:gr-03) se observa que el ACF decae y el PACF se corta en 2. Un modelo
candidato sería el **AR(2) o ARIMA(2, 0, 0)**. También podríamos decir que el PACF decae con
un corte en el retardo p = 3 en el ACF, por lo que otro modelo candidato sería un MA(3), es
decir ARIMA(0, 0, 3)
</p>

## Auto ARIMA

> Debido a que cortar una serie temporal en entrenamiento y prueba significa trabajar con
datos de dos períodos distintos. Si existe algún cambio en los patrones principales en esos
períodos, no tendría sentido hacerlo. De echo una opción en estos casos es detectar puntos de
cambio en la serie temporal y, de ser posible por el tamaño, ajustar modelos distintos para
los períodos identificados. Por tanto, no hay un único procedimiento correcto, depende del
caso. 

Con base a lo anterior, vamos a utilizar **todo** el conjunto de datos para encontrar el
mejor modelo con `auto.arima()` y posteriormente realizaremos validación cruzada para
evaluar su capacidad predictiva.

Realizaremos el ajuste considerando los modelos observados AR(2) y MA(3) para luego dejar que
la función `auto.arima()` busque primeramente con valores por defectos y luego la haremos
buscar con los parámetros `stepwise = FALSE` y `greedy = FALSE` para que realice una búsqueda
profunda.

`r resaltar("Será necesario ajustar modelos alternativos:")`

```{r}
fit <- volcan |> 
 model(ar2  = ARIMA(value ~ 1 + pdq(2, 0, 0)),
       ma3  = ARIMA(value ~ 1 + pdq(0, 0, 3)),
       stepwise = ARIMA(value),
       busqueda = ARIMA(value, stepwise = FALSE, greedy = FALSE),
       preciso  = ARIMA(value, stepwise = FALSE, approximation = FALSE, greedy = FALSE))
```

```{r, paged.print = FALSE}
fit |>
 pivot_longer(everything(),
 				  names_to  = "modelo",
 				  values_to = "orden")
```


```{r}
c(t1, t2) %<-% ajustar_modelos(fit, fun_list)
```

```{r}
t2 |> tabla(cap = "Bondad de ajuste")
```

</br>

## Mejor AIC

Seleccionemos el mejor modelo que nos da la mejor bondad de ajuste en el conjunto de
entrenamiento

```{r}
best_gof_model <- t2 |> 
 slice_min(order_by = AICc) |> 
 pull(.model)
```

```{r}
best_gof_model
```

Tenemos un vector con dos modelos debido a que tanto mi modelo candidato seleccionado
manualmente como la el obtenido con auto.arima en modo exhaustivo son **coincidentes**.


# Interpretación

`r resaltar("¿coincide con tus modelos candidatos?")`

<p class="comment">
El modelo con menor AICc es el que determinamos a partir de las gráficas ACF y PACF y que
llamamos `r best_gof_model[1]`. El modelo obtenido con auto.arima **coincide con mi modelo
candidato seleccionado manualmente.**
</p>

`r resaltar("¿Qué tipo de modelo has obtenido?")`

<p class="comment">
El modelo obtenido es un AR(2), el cual es consistente con lo previamente explicado en el
gráfico \@ref(fig:gr-02) y en la tabla \@ref(tab:retar).  Vemos que el ACF decae y el PACF se
corta en 2.
</p>

# Diagnóstico

Realicemos un diagnóstico del mejor modelo obtenido con auto.arima para que después lo
podamos comparar con validación cruzada.

(ref:gr-04) Resumen gráfico

```{r, gr-04, fig.cap='(ref:gr-04)'}
fit |> 
 select(any_of(best_gof_model[1])) |> 
 gg_tsresiduals() +
 labs(title = "Análisis de residuos")
```

<br/>

<p class="comment">
En el gráfico \@ref(fig:gr-04) se observa que los residuos no muestran un patrón evidente. 
Uno de los bastones se sale de los límites, pero es probable que esto se deba al azar
(esperaríamos que 1 de cada 20 retardos exceda los límites de significación del 95% solo 
or azar). La distribución de los residuos se ve bastante normal.
</p>

```{r}
augment(fit) |> 
 filter(.model == "ar2") |> 
 features(.innov, ljung_box, lag = 10, dof = 3) |> 
 tabla(cap = "Los residuos son ruido blanco")
```

</br>

<p class="comment">
Una prueba de *portmanteau* arroja un p-valor grande, lo que también sugiere que **los
residuos son ruido blanco**.
</p>

# Validación Cruzada

Probaremos dos métodos y evaluaremos que tan parecido es su RMSE para un horizonte de 5
años

## Método forecast::tsCV()

```{r, echo=FALSE}
# corrida manual
# ruta <- fs::path_wd("08_series_tiempo", "ejercicios_obligatorios", "objetos")
# tablero <- board_folder(path = ruta)

# corrida en knit 
tablero <- board_folder(path = "./objetos")
```


```{r, eval=FALSE}
# primera función
far2 <- function(x, h){forecast(Arima(x, order = c(2,0,0)), h = h)}
ar2_tscv <- tsCV(ts(volcan_raw, start = c(1500)), far2, h = 1)
```

```{r, eval=FALSE, echo=FALSE}
pin_write(board = tablero,
			 x     = ar2_tscv,
			 name  = "ar2_tsCV",
			 type  = "rds",
			 title = "objeto_ar2",
			 description = "primer_modelo")
```

```{r, echo=FALSE}
ar2_tscv <- pin_read(board = tablero, name = "ar2_tsCV")
```

```{r}
sqrt(mean(ar2_tscv^2, na.rm=TRUE)) 
```


```{r, eval=FALSE}
far2 <- function(x, h){forecast(Arima(x, order=c(0,0,3)), h=h)}
ma3_tscv <- tsCV(ts(volcan_raw, start = c(1500)), far2, h = 1)
```


```{r, eval=FALSE, echo=FALSE}
pin_write(board = tablero,
			 x     = ma3_tscv,
			 name  = "ma3_tsCV",
			 type  = "rds",
			 title = "objeto_ma3",
			 description = "segundo_modelo")
```

```{r, echo=FALSE}
ma3_tscv <- pin_read(board = tablero, name = "ma3_tscv")
```

```{r}
sqrt(mean(ma3_tscv^2, na.rm=TRUE)) 
```


## Método tsibble::stretch_tsibble()

A continuación, comparamos la precisión obtenida a través de la validación cruzada de series
temporales con la precisión residual. La función `stretch_tsibble()` la usaremos para crear
muchos conjuntos de entrenamiento. En este caso, comenzaremos con un conjunto de
entrenamiento de longitud `.init = 3`  y aumentamos el tamaño de los conjuntos de
entrenamiento sucesivos en `.step = 1.`

```{r}
volcan_tr <- volcan |> 
 stretch_tsibble(.init = 3, .step = 1)
```

Con base a los resultados de la función auto.arima, comparemos dos modelos candidatos, los
cuales obtuvieron las mejores puntuaciones de AICc en cuanto a residuos en la parte de
capacitación.  Ahora veamos como se ven los resultados de estos modelos, pero ahora utilizando
CV y RMSE como métrica de desempeño final.

Comencemos definiendo una lista de modelos candidatos.

```{r}
candidatos <- list(ar2 = c(2, 0, 0), ma3 = c(0, 0, 3))
```

Creamos una función que nos ayude a iterar sobre ambos modelos

```{r}
com <- function(stretch_ts, tsb, nm, pdq, horizonte = 1) {
 c(p, d, q) %<-% as.list(pdq)	
 nm <- rlang::sym(nm)
	
 stretch_ts |> 
  model({{ nm }} := ARIMA(value ~ 1 + pdq(p, d, q))) |> 
  forecast(h = horizonte) |> 
  group_by(.id) |>
  mutate(h = row_number()) |>
  ungroup() |>
  as_fable(response = "value", distribution = value) |>
  accuracy(tsb, by = c("h", ".model")) |>
  select(h, .model, RMSE) |> 
  rename(modelo = .model)
}
```

Por facilidad, guardemos los argumentos en una lista

```{r}
args <- list(stretch_ts = volcan_tr, tsb = volcan)
```

Iteremos con un horizonte de 5 años.

```{r, eval=FALSE}
res <- candidatos |> 
 imap(~ exec("com", !!!args, nm = .y, pdq = .x, horizonte = 5)) |> 
 bind_rows()
```


```{r, eval=FALSE, echo=FALSE}
pin_write(board = tablero,
			 x     = res,
			 name  = "res_stretch",
			 type  = "rds",
			 title = "objeto_stretch",
			 description = "mejor_cv")
```

```{r, echo=FALSE}
res <- pin_read(board = tablero, name = "res_stretch")
```


(ref:gr-07) Resumen gráfico

```{r, gr-07, fig.cap='(ref:gr-07)'}
res |> 
 ggplot(aes(x = h, y = RMSE)) +
 geom_point(aes(shape = modelo, color = modelo), size = 5) +
 labs(title = glue("Desempeño de los modelos para un horizonte de 5 años"),
  	   subtitle = "Observar cómo cambia la exactitud de las predicciones cuando se aleja más el dato a predecir")
```

<br/>

En el gráfico \@ref(fig:gr-07) se observa que el método `forecast::tsCV()` y el método
`tsibble::stretch_tsibble()` `r resaltar("arrojan resultados similares en cuanto a el RMSE
del primer año, tanto para AR(2) como para MA(3)")`

<p class="comment">
Vemos que el modelo AR2 tiene un menor error de pronóstico con CV en los primeros 2 años,
sin embargo, el modelo MA3 tiene un menor error en el año 4 y 5
</p>

# Predecir

(ref:gr-06) Para que sea más fácil de visualizar, realizamos una predicción hasta el año 2023

```{r, gr-06, fig.cap='(ref:gr-06)'}
fit |> 
 forecast(h = 54) |> 
 filter(.model == "ar2") |> 
 autoplot(volcan)
```

<br/>

```{r, coef}
t1 |> tabla(cap = "Coeficientes")
```

</br>

La función `fable::ARIMA()` utiliza una parametrización alternativa de constantes a la de
`stats::arima()` y `forecast::Arima()`. Si bien las parametrizaciones son equivalentes,
`r resaltar("los coeficientes para la constante/media que nos da fable::ARIMA() serán
diferentes a las de stats::arima() y forecast::Arima()")`.
Ver https://bit.ly/36gbLP3


</br>

# Conclusiones

`r resaltar("Las previsiones parecen razonables")`

<p class="comment">
En el gráfico \@ref(fig:gr-06) se observa la linea azul la cual representa la predicción
media de nuestro modelo. Aquí estamos utilizando el modelo que nos entregó un mejor RMSE con
cross-validación.  En la tabla \@ref(tab:coef) vemos los coeficientes de los modelos.
Sabemos que si $c \neq 0$ y $d = 0$ los pronósticos a largo plazo irán a la media de los
datos. Vemos en la figura \@ref(fig:gr-06) que los intervalos de predicción tienen casi el
mismo ancho para los últimos horizontes de pronósticos y los pronósticos de puntos finales
están cerca de la media de los datos. 
</p>


# Bibliografía



















